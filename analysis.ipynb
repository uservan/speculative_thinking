{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc, wrong avg tokens, right avg tokens, avg flops, corrct_tokens_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxy320/miniconda3/envs/multio1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "configs = {\n",
    "    '1b': AutoConfig.from_pretrained('Qwen/Qwen2.5-1.5B-Instruct'),\n",
    "    '7b': AutoConfig.from_pretrained('Qwen/Qwen2.5-7B-Instruct'),\n",
    "    '14b': AutoConfig.from_pretrained('Qwen/Qwen2.5-14B-Instruct'),\n",
    "    '32b': AutoConfig.from_pretrained('Qwen/Qwen2.5-32B-Instruct')\n",
    "}\n",
    "\n",
    "def many_decode_flops(p_l, s, h, h_, n):\n",
    "    return 8*s*(h^2) + 16*s*h + 4*s*p_l*h + 4*s*p_l*n + 6*s*h*h_ + 2*s*h_\n",
    "\n",
    "def prefill_flop(s, h, h_, n):\n",
    "    return 8*s*(h^2) + 16*s*h + 4*(s^2)*h + 4*(s^2)*n + 6*s*h*h_ + 2*s*h_\n",
    "\n",
    "def decode_flop(s, h, h_, n):\n",
    "    return 8*(h^2) + 16*h + 4*s*h + 4*s*n + 6*h*h_ + 2*h_\n",
    "\n",
    "def cum_decode_flop(p_l, l, h, h_, n):\n",
    "    flops = 0\n",
    "    for i in range(l):\n",
    "        flops = flops + decode_flop(p_l+i, h, h_, n)\n",
    "    return flops\n",
    "\n",
    "def get_flops(name, help_model, token_usages):\n",
    "    correct_num = 0\n",
    "    if help_model not in configs.keys():\n",
    "        config = configs[name]\n",
    "        info= config.hidden_size, config.intermediate_size, config.num_attention_heads\n",
    "        flops = prefill_flop(token_usages['prompt_tokens'], *info) + cum_decode_flop(token_usages['prompt_tokens'], token_usages['completion_tokens'], *info)\n",
    "    else:\n",
    "        spe_config = configs[name]\n",
    "        tgt_config = configs[help_model]\n",
    "        spe_info = spe_config.hidden_size, spe_config.intermediate_size, spe_config.num_attention_heads\n",
    "        tgt_info = tgt_config.hidden_size, tgt_config.intermediate_size, tgt_config.num_attention_heads\n",
    "        correct_tokens = token_usages['correct_tokens']\n",
    "        completion_tokens = token_usages['completion_tokens']\n",
    "        prompt_tokens = token_usages['prompt_tokens']\n",
    "        decode_spe_flops, decode_tgt_flops = 0, 0\n",
    "        last_spe_decode_pos = prompt_tokens\n",
    "        token_num = 0\n",
    "        decode_spe_flops = decode_spe_flops+prefill_flop(prompt_tokens, *spe_info)\n",
    "        decode_tgt_flops = decode_tgt_flops+prefill_flop(prompt_tokens, *tgt_info)\n",
    "        for cor_t in correct_tokens:\n",
    "            pos, token_num = cor_t['pos']+prompt_tokens-token_num, cor_t['token_num']\n",
    "            decode_spe_flops = decode_spe_flops+cum_decode_flop(last_spe_decode_pos, pos-last_spe_decode_pos, *spe_info)\n",
    "            decode_tgt_flops = decode_tgt_flops+many_decode_flops(last_spe_decode_pos, pos-last_spe_decode_pos, *tgt_info)\n",
    "            decode_tgt_flops = decode_tgt_flops+cum_decode_flop(pos, token_num, *tgt_info)\n",
    "            decode_spe_flops = decode_spe_flops+many_decode_flops(pos, token_num, *spe_info)\n",
    "            correct_num = correct_num + token_num\n",
    "            last_spe_decode_pos = pos\n",
    "        decode_spe_flops = decode_spe_flops+cum_decode_flop(last_spe_decode_pos+token_num, completion_tokens+prompt_tokens-last_spe_decode_pos-token_num, *spe_info)\n",
    "        # print(token_usages)\n",
    "        flops = decode_spe_flops+decode_tgt_flops\n",
    "    return flops, correct_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7b 32b\n",
      "dict_keys(['problem', 'solution', 'answer', 'subject', 'level', 'unique_id', 'responses', 'token_usages', 'prompt', 'input_conversation'])\n",
      "{'completion_tokens': 1534, 'prompt_tokens': 67, 'correct_tokens': [{'pos': 629, 'token_num': 20, 'traget': 'Wait, let me double-check that. 3 is 9/3, adding 5/', 'speculative': 'Wait, let me check that again. 3 is indeed 9/3, so 9'}, {'pos': 649, 'token_num': 125, 'traget': \"3 gives 14/3. Yeah, that's correct. So, the total is 14/3. Hmm, is that the simplest form? 14 and 3 don't have any common factors besides 1, so yes, 14/3 is the simplified form.\\n\\nLet me just verify each step to make sure I didn't make a mistake. \\n\\nFirst, f(-2): 3*(-2) is -6, minus 2 is -8. Denominator: -2 - 2 is -4. So, -8/-4 is 2. That seems\"}, {'pos': 924, 'token_num': 20, 'traget': 'Wait, just to make sure, maybe I can compute the sum another way. Let me add all', 'speculative': 'Wait, just thinking about the function, is there a simpler way to approach this? Maybe, but'}, {'pos': 1067, 'token_num': 20, 'traget': '**Final Answer**\\nThe value of \\\\( f(-2) + f(-1) + f(', 'speculative': '**Final Answer**\\nThe value of \\\\( f(-2) + f(-1) + f('}], 'time_spend': 28.25077724456787, 'try_correct': 4}\n",
      "1593345228688\n"
     ]
    }
   ],
   "source": [
    "print(name, model)\n",
    "t=0.6\n",
    "spe_config = configs[name]\n",
    "tgt_config = configs[model]\n",
    "spe_info = spe_config.hidden_size, spe_config.intermediate_size, spe_config.num_attention_heads\n",
    "tgt_info = tgt_config.hidden_size, tgt_config.intermediate_size, tgt_config.num_attention_heads\n",
    "for k in data.keys():\n",
    "    print(data[k].keys())\n",
    "    token_usages = data[k]['token_usages'][str(t)][0]\n",
    "    correct_tokens = token_usages['correct_tokens']\n",
    "    completion_tokens = token_usages['completion_tokens']\n",
    "    prompt_tokens = token_usages['prompt_tokens']\n",
    "    decode_spe_flops, decode_tgt_flops = 0, 0\n",
    "    last_spe_decode_pos = completion_tokens\n",
    "    correct_num, token_num = 0, 0\n",
    "    for cor_t in correct_tokens:\n",
    "        pos, token_num = cor_t['pos']+prompt_tokens, cor_t['token_num']\n",
    "        decode_spe_flops = decode_spe_flops+cum_decode_flop(last_spe_decode_pos, pos-last_spe_decode_pos, *spe_info)\n",
    "        decode_tgt_flops = decode_tgt_flops+cum_decode_flop(pos, token_num, *tgt_info)\n",
    "        correct_num = correct_num + token_num\n",
    "        last_spe_decode_pos = pos\n",
    "    decode_spe_flops = decode_spe_flops+prefill_flop(correct_num+prompt_tokens, *spe_info)\n",
    "    decode_tgt_flops = decode_tgt_flops+prefill_flop(completion_tokens-correct_num, *tgt_info)\n",
    "    print(token_usages)\n",
    "    flops = decode_spe_flops+decode_tgt_flops\n",
    "    print(flops)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_info(data, name, help_model, t=0.6):\n",
    "    correct_num, correct_tokens, worng_tokens, all_time_spend = 0, 0, 0, 0\n",
    "    fix_tokens, right_flops, wrong_flops, all_flops = 0, 0, 0, 0\n",
    "    for k in data.keys():\n",
    "        # print(data[k].keys())\n",
    "        token_usages = data[k]['token_usages'][str(t)][0]\n",
    "        # time_spend = token_usages['time_spend']\n",
    "        tokens_num = token_usages['completion_tokens']\n",
    "        flops, fix_token = get_flops(name, help_model, token_usages)\n",
    "        if data[k]['responses'][str(t)][0]['correctness']: \n",
    "            correct_num = correct_num+1\n",
    "            correct_tokens = correct_tokens+tokens_num\n",
    "            right_flops = right_flops+flops\n",
    "        else:\n",
    "            worng_tokens = worng_tokens+tokens_num\n",
    "            wrong_flops = wrong_flops+flops\n",
    "        all_flops = all_flops+flops\n",
    "        fix_tokens = fix_tokens+fix_token\n",
    "        #  all_time_spend = all_time_spend + time_spend\n",
    "    all_num = len(data.keys())\n",
    "    r = 10000000000\n",
    "    return {\n",
    "        'all_num':all_num,\n",
    "        'acc':round(correct_num/all_num, 4),\n",
    "        'correct_avg_tokens':round(correct_tokens/correct_num, 2),\n",
    "        'worng_avg_tokens':round(worng_tokens/(all_num-correct_num), 2),\n",
    "        # 'right_flops': round(right_flops/(correct_num*r), 2),\n",
    "        # 'wrong_flops': round(wrong_flops/((all_num-correct_num)*r), 2),\n",
    "        'avg_flops': round(all_flops/(all_num*r), 2),\n",
    "        #  'avg_time_spend': round((correct_tokens+worng_tokens)/all_time_spend, 2),\n",
    "        'fix_tokens': round(fix_tokens/(correct_tokens+worng_tokens),2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(dict)\n",
    "\n",
    "folder_path = \"/home/wxy320/ondemand/program/speculative_thinking/analysis/1/normal\"  # 替换为你的文件夹路径\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith(\".json\")]\n",
    "for file in json_files:\n",
    "    name = file.split('_')[0].split('-')[-1].lower()\n",
    "    if name == '1.5b': name = '1b'\n",
    "    dataset = file.split('_')[1]\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        result = get_info(data, name, None)\n",
    "    results[(name,dataset)] = {\n",
    "        'normal': result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/wxy320/ondemand/program/speculative_thinking/analysis/1/speculative\"  # 替换为你的文件夹路径\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith(\".json\")]\n",
    "\n",
    "for file in json_files:\n",
    "    name, model, dataset = file.split('_')[0], file.split('_')[1].split('.')[0], file.split('_')[2]\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        result = get_info(data, name, model)\n",
    "        # print(result)\n",
    "    results[(name,dataset)][model] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aime22\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 30, 'acc': 0.3, 'correct_avg_tokens': 9296.56, 'worng_avg_tokens': 21558.86, 'avg_flops': 279.74, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.3333, 'correct_avg_tokens': 7319.2, 'worng_avg_tokens': 22248.6, 'avg_flops': 1643.81, 'fix_tokens': 0.17}\n",
      "32b {'all_num': 30, 'acc': 0.2667, 'correct_avg_tokens': 7282.12, 'worng_avg_tokens': 18987.59, 'avg_flops': 2153.17, 'fix_tokens': 0.17}\n",
      "7b\n",
      "normal {'all_num': 30, 'acc': 0.5, 'correct_avg_tokens': 9178.8, 'worng_avg_tokens': 16906.67, 'avg_flops': 720.87, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.4667, 'correct_avg_tokens': 9469.93, 'worng_avg_tokens': 22208.62, 'avg_flops': 2302.67, 'fix_tokens': 0.18}\n",
      "32b {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 7540.53, 'worng_avg_tokens': 22824.08, 'avg_flops': 2645.4, 'fix_tokens': 0.18}\n",
      "14b\n",
      "normal {'all_num': 30, 'acc': 0.6, 'correct_avg_tokens': 7878.28, 'worng_avg_tokens': 22725.0, 'avg_flops': 873.5, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 7503.65, 'worng_avg_tokens': 21042.08, 'avg_flops': 1405.91, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "aime23\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 30, 'acc': 0.2, 'correct_avg_tokens': 6247.33, 'worng_avg_tokens': 20482.12, 'avg_flops': 272.91, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.2333, 'correct_avg_tokens': 5394.29, 'worng_avg_tokens': 21799.65, 'avg_flops': 1715.58, 'fix_tokens': 0.19}\n",
      "32b {'all_num': 30, 'acc': 0.2, 'correct_avg_tokens': 11683.0, 'worng_avg_tokens': 20803.83, 'avg_flops': 2613.2, 'fix_tokens': 0.2}\n",
      "7b\n",
      "normal {'all_num': 30, 'acc': 0.3667, 'correct_avg_tokens': 7842.73, 'worng_avg_tokens': 17261.95, 'avg_flops': 767.25, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 7878.41, 'worng_avg_tokens': 18862.69, 'avg_flops': 1749.69, 'fix_tokens': 0.19}\n",
      "32b {'all_num': 30, 'acc': 0.4667, 'correct_avg_tokens': 7013.93, 'worng_avg_tokens': 18907.62, 'avg_flops': 2472.81, 'fix_tokens': 0.18}\n",
      "14b\n",
      "normal {'all_num': 30, 'acc': 0.5333, 'correct_avg_tokens': 7431.38, 'worng_avg_tokens': 20517.57, 'avg_flops': 876.1, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 30, 'acc': 0.6, 'correct_avg_tokens': 8543.56, 'worng_avg_tokens': 19537.5, 'avg_flops': 1359.18, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "aime24\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 30, 'acc': 0.2667, 'correct_avg_tokens': 7457.25, 'worng_avg_tokens': 21669.91, 'avg_flops': 285.15, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.4333, 'correct_avg_tokens': 7791.92, 'worng_avg_tokens': 20211.35, 'avg_flops': 1301.14, 'fix_tokens': 0.18}\n",
      "32b {'all_num': 30, 'acc': 0.5, 'correct_avg_tokens': 6680.4, 'worng_avg_tokens': 17864.33, 'avg_flops': 1639.42, 'fix_tokens': 0.18}\n",
      "7b\n",
      "normal {'all_num': 30, 'acc': 0.6, 'correct_avg_tokens': 8194.17, 'worng_avg_tokens': 19959.58, 'avg_flops': 712.9, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 6437.29, 'worng_avg_tokens': 18719.31, 'avg_flops': 1568.13, 'fix_tokens': 0.18}\n",
      "32b {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 6002.82, 'worng_avg_tokens': 20119.69, 'avg_flops': 2124.27, 'fix_tokens': 0.17}\n",
      "14b\n",
      "normal {'all_num': 30, 'acc': 0.6667, 'correct_avg_tokens': 6988.45, 'worng_avg_tokens': 17359.2, 'avg_flops': 613.06, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 30, 'acc': 0.8, 'correct_avg_tokens': 9594.46, 'worng_avg_tokens': 14179.67, 'avg_flops': 1067.96, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "gpqa\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 198, 'acc': 0.3384, 'correct_avg_tokens': 8556.21, 'worng_avg_tokens': 7597.59, 'avg_flops': 110.75, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 198, 'acc': 0.3889, 'correct_avg_tokens': 6623.31, 'worng_avg_tokens': 9095.91, 'avg_flops': 532.4, 'fix_tokens': 0.15}\n",
      "32b {'all_num': 198, 'acc': 0.4192, 'correct_avg_tokens': 5518.86, 'worng_avg_tokens': 7211.23, 'avg_flops': 750.31, 'fix_tokens': 0.19}\n",
      "7b\n",
      "normal {'all_num': 198, 'acc': 0.4545, 'correct_avg_tokens': 5301.43, 'worng_avg_tokens': 6786.46, 'avg_flops': 307.02, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 198, 'acc': 0.4646, 'correct_avg_tokens': 4089.74, 'worng_avg_tokens': 6918.5, 'avg_flops': 680.68, 'fix_tokens': 0.22}\n",
      "32b {'all_num': 198, 'acc': 0.5202, 'correct_avg_tokens': 5009.54, 'worng_avg_tokens': 6974.79, 'avg_flops': 1011.51, 'fix_tokens': 0.22}\n",
      "14b\n",
      "normal {'all_num': 198, 'acc': 0.5707, 'correct_avg_tokens': 4574.1, 'worng_avg_tokens': 7342.75, 'avg_flops': 311.13, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 198, 'acc': 0.6162, 'correct_avg_tokens': 4481.6, 'worng_avg_tokens': 6891.96, 'avg_flops': 534.08, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "math500\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 500, 'acc': 0.832, 'correct_avg_tokens': 3520.69, 'worng_avg_tokens': 14939.94, 'avg_flops': 69.96, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 500, 'acc': 0.89, 'correct_avg_tokens': 3511.49, 'worng_avg_tokens': 12746.58, 'avg_flops': 334.19, 'fix_tokens': 0.19}\n",
      "32b {'all_num': 500, 'acc': 0.894, 'correct_avg_tokens': 3563.96, 'worng_avg_tokens': 13175.55, 'avg_flops': 563.29, 'fix_tokens': 0.19}\n",
      "7b\n",
      "normal {'all_num': 500, 'acc': 0.928, 'correct_avg_tokens': 3245.22, 'worng_avg_tokens': 13384.03, 'avg_flops': 194.79, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 500, 'acc': 0.924, 'correct_avg_tokens': 3406.71, 'worng_avg_tokens': 12472.05, 'avg_flops': 463.73, 'fix_tokens': 0.17}\n",
      "32b {'all_num': 500, 'acc': 0.93, 'correct_avg_tokens': 3271.67, 'worng_avg_tokens': 10359.26, 'avg_flops': 603.38, 'fix_tokens': 0.18}\n",
      "14b\n",
      "normal {'all_num': 500, 'acc': 0.938, 'correct_avg_tokens': 3161.06, 'worng_avg_tokens': 10386.29, 'avg_flops': 187.37, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 500, 'acc': 0.928, 'correct_avg_tokens': 3109.74, 'worng_avg_tokens': 12726.53, 'avg_flops': 368.24, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "olympiadbench\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 674, 'acc': 0.4496, 'correct_avg_tokens': 4977.9, 'worng_avg_tokens': 14496.71, 'avg_flops': 149.34, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 71, 'acc': 0.7183, 'correct_avg_tokens': 2846.47, 'worng_avg_tokens': 2347.6, 'avg_flops': 159.63, 'fix_tokens': 0.18}\n",
      "7b\n",
      "normal {'all_num': 674, 'acc': 0.5757, 'correct_avg_tokens': 4710.14, 'worng_avg_tokens': 13684.28, 'avg_flops': 456.83, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 137, 'acc': 0.7518, 'correct_avg_tokens': 2326.21, 'worng_avg_tokens': 2140.53, 'avg_flops': 214.9, 'fix_tokens': 0.15}\n",
      "14b\n",
      "normal {'all_num': 674, 'acc': 0.6454, 'correct_avg_tokens': 5074.7, 'worng_avg_tokens': 11516.15, 'avg_flops': 427.72, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 674, 'acc': 0.681, 'correct_avg_tokens': 4905.61, 'worng_avg_tokens': 11664.35, 'avg_flops': 716.54, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "livecodebench\n",
      "------------------------\n",
      "7b\n",
      "14b {'all_num': 93, 'acc': 0.9355, 'correct_avg_tokens': 2063.54, 'worng_avg_tokens': 2041.17, 'avg_flops': 226.18, 'fix_tokens': 0.2}\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "final_results = defaultdict(dict)\n",
    "for key, r in results.items():\n",
    "    # print(key)\n",
    "    final_results[key[1]][key[0]]=r\n",
    "for d, r in final_results.items():\n",
    "    print(d)\n",
    "    print('------------------------')\n",
    "    for k, r_ in r.items():\n",
    "        print(k)\n",
    "        for k_, r_1 in r_.items():\n",
    "            print(k_, r_1)\n",
    "    print('------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multio1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
