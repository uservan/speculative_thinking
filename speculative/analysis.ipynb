{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc, wrong avg tokens, right avg tokens, avg flops, corrct_tokens_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxy320/miniconda3/envs/multio1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt_len': 50, 'generate_n': 0.8202776908874512, 'generate_last': 0.05501508712768555, 'ratio': 14.910049837486458}, {'prompt_len': 500, 'generate_n': 0.35877037048339844, 'generate_last': 0.053021907806396484, 'ratio': 6.766455326228696}, {'prompt_len': 1024, 'generate_n': 0.45013928413391113, 'generate_last': 0.04739665985107422, 'ratio': 9.497278617276}, {'prompt_len': 4096, 'generate_n': 0.2528512477874756, 'generate_last': 0.030248641967773438, 'ratio': 8.359094205183176}, {'prompt_len': 8192, 'generate_n': 0.25091099739074707, 'generate_last': 0.030231714248657227, 'ratio': 8.29959542905813}, {'prompt_len': 12288, 'generate_n': 0.25008678436279297, 'generate_last': 0.0373539924621582, 'ratio': 6.695048316887295}, {'prompt_len': 15360, 'generate_n': 0.2595670223236084, 'generate_last': 0.0434720516204834, 'ratio': 5.970894233142293}]\n",
      "[{'prompt_len': 50, 'generate_n': 0.4940340518951416, 'generate_last': 0.03111410140991211, 'ratio': 15.878139798623776}, {'prompt_len': 500, 'generate_n': 0.4982295036315918, 'generate_last': 0.029937744140625, 'ratio': 16.64218590723751}, {'prompt_len': 1024, 'generate_n': 0.4940066337585449, 'generate_last': 0.031206369400024414, 'ratio': 15.830314235726455}, {'prompt_len': 4096, 'generate_n': 0.496044397354126, 'generate_last': 0.030132532119750977, 'ratio': 16.46208806424813}, {'prompt_len': 8192, 'generate_n': 0.4960653781890869, 'generate_last': 0.030353546142578125, 'ratio': 16.342913472414228}, {'prompt_len': 12288, 'generate_n': 0.4969971179962158, 'generate_last': 0.03845524787902832, 'ratio': 12.924038860954907}, {'prompt_len': 15360, 'generate_n': 0.49785494804382324, 'generate_last': 0.044767141342163086, 'ratio': 11.120990376370715}]\n",
      "[{'prompt_len': 50, 'generate_n': 3.0538222789764404, 'generate_last': 0.031078100204467773, 'ratio': 98.26283649530882}, {'prompt_len': 500, 'generate_n': 3.074289083480835, 'generate_last': 0.030401945114135742, 'ratio': 101.12146022036623}, {'prompt_len': 1024, 'generate_n': 3.0681002140045166, 'generate_last': 0.03416776657104492, 'ratio': 89.79516432907683}, {'prompt_len': 4096, 'generate_n': 3.072859287261963, 'generate_last': 0.03043222427368164, 'ratio': 100.97386440199934}, {'prompt_len': 8192, 'generate_n': 3.0705156326293945, 'generate_last': 0.03300905227661133, 'ratio': 93.02041170097509}, {'prompt_len': 12288, 'generate_n': 3.064915657043457, 'generate_last': 0.04186296463012695, 'ratio': 73.21305798867792}, {'prompt_len': 15360, 'generate_n': 3.0689127445220947, 'generate_last': 0.04854989051818848, 'ratio': 63.211527601125546}]\n",
      "[{'prompt_len': 50, 'generate_n': 6.122892618179321, 'generate_last': 0.031171083450317383, 'ratio': 196.4286107647945}, {'prompt_len': 500, 'generate_n': 6.136996269226074, 'generate_last': 0.030300140380859375, 'ratio': 202.54019262243483}, {'prompt_len': 1024, 'generate_n': 6.130053281784058, 'generate_last': 0.03387880325317383, 'ratio': 180.94066770820137}, {'prompt_len': 4096, 'generate_n': 6.139526128768921, 'generate_last': 0.030188798904418945, 'ratio': 203.37099691204457}, {'prompt_len': 8192, 'generate_n': 6.158326625823975, 'generate_last': 0.03541254997253418, 'ratio': 173.90237728151024}, {'prompt_len': 12288, 'generate_n': 6.130600452423096, 'generate_last': 0.04451441764831543, 'ratio': 137.72168156523324}, {'prompt_len': 15360, 'generate_n': 6.125217914581299, 'generate_last': 0.05117917060852051, 'ratio': 119.68185185012648}]\n"
     ]
    }
   ],
   "source": [
    "import __init__\n",
    "from speculative.test import *\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"  # or your model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "tokenizer.pad_token = tokenizer.pad_token or tokenizer.eos_token\n",
    "for n in [10, 20, 125, 250]:\n",
    "    results = benchmark_final_token_latency_by_prompt_len(model, tokenizer, n_generate=n)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.193986856246504e-09, 1.048496714061626e-09)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configs['32b']\n",
    "info = config.hidden_size, config.intermediate_size, config.num_attention_heads\n",
    "\n",
    "p_l, l = 5000, 100\n",
    "l/many_decode_flops(p_l, l, *info), l/cum_decode_flop(p_l, l, *info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxy320/miniconda3/envs/multio1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "configs = {\n",
    "    '1b': AutoConfig.from_pretrained('Qwen/Qwen2.5-1.5B-Instruct'),\n",
    "    '1b-instruct': AutoConfig.from_pretrained('Qwen/Qwen2.5-1.5B-Instruct'),\n",
    "    '7b': AutoConfig.from_pretrained('Qwen/Qwen2.5-7B-Instruct'),\n",
    "    '7b-instruct': AutoConfig.from_pretrained('Qwen/Qwen2.5-7B-Instruct'),\n",
    "    '14b': AutoConfig.from_pretrained('Qwen/Qwen2.5-14B-Instruct'),\n",
    "    '14b-instruct': AutoConfig.from_pretrained('Qwen/Qwen2.5-14B-Instruct'),\n",
    "    '32b': AutoConfig.from_pretrained('Qwen/Qwen2.5-32B-Instruct'),\n",
    "    '32b-instruct': AutoConfig.from_pretrained('Qwen/Qwen2.5-32B-Instruct')\n",
    "}\n",
    "\n",
    "def many_decode_flops(p_l, s, h, h_, n):\n",
    "    # return 8*s*(h^2) + 16*s*h + 4*s*p_l*h + 4*s*p_l*n + 6*s*h*h_ + 2*s*h_\n",
    "    return cum_decode_flop(p_l, s, h, h_, n)/5\n",
    "\n",
    "def prefill_flop(s, h, h_, n):\n",
    "    return 8*s*(h^2) + 16*s*h + 4*(s^2)*h + 4*(s^2)*n + 6*s*h*h_ + 2*s*h_\n",
    "\n",
    "def decode_flop(s, h, h_, n):\n",
    "    return 8*(h^2) + 16*h + 4*s*h + 4*s*n + 6*h*h_ + 2*h_\n",
    "\n",
    "def cum_decode_flop(p_l, l, h, h_, n):\n",
    "    flops = 0\n",
    "    for i in range(l):\n",
    "        flops = flops + decode_flop(p_l+i, h, h_, n)\n",
    "    return flops\n",
    "\n",
    "def get_flops(name, help_model, token_usages):\n",
    "    correct_num = 0\n",
    "    prefill_flops, prefix_flops, decode_flops=0,0,0\n",
    "    if help_model not in configs.keys():\n",
    "        config = configs[name]\n",
    "        info= config.hidden_size, config.intermediate_size, config.num_attention_heads\n",
    "        prefill_flops = prefill_flop(token_usages['prompt_tokens'], *info) \n",
    "        decode_flops = cum_decode_flop(token_usages['prompt_tokens'], token_usages['completion_tokens'], *info)\n",
    "    else:\n",
    "        spe_config = configs[name]\n",
    "        tgt_config = configs[help_model]\n",
    "        spe_info = spe_config.hidden_size, spe_config.intermediate_size, spe_config.num_attention_heads\n",
    "        tgt_info = tgt_config.hidden_size, tgt_config.intermediate_size, tgt_config.num_attention_heads\n",
    "        correct_tokens = token_usages['correct_tokens']\n",
    "        completion_tokens = token_usages['completion_tokens']\n",
    "        prompt_tokens = token_usages['prompt_tokens']\n",
    "        last_spe_decode_pos = prompt_tokens\n",
    "        token_num = 0\n",
    "        prefill_flops = prefill_flops+prefill_flop(prompt_tokens, *spe_info)\n",
    "        prefill_flops = prefill_flops+prefill_flop(prompt_tokens, *tgt_info)\n",
    "        for cor_t in correct_tokens:\n",
    "            pos, token_num = cor_t['pos']+prompt_tokens, cor_t['token_num']\n",
    "            decode_flops = decode_flops+cum_decode_flop(last_spe_decode_pos, pos-last_spe_decode_pos, *spe_info)\n",
    "            f = many_decode_flops(last_spe_decode_pos, pos-last_spe_decode_pos, *tgt_info)\n",
    "            prefix_flops = prefix_flops+f #*f/cum_decode_flop(last_spe_decode_pos, pos-last_spe_decode_pos, *tgt_info)\n",
    "            decode_flops = decode_flops+cum_decode_flop(pos, token_num, *tgt_info)\n",
    "            f = many_decode_flops(pos, token_num, *spe_info)\n",
    "            prefix_flops = prefix_flops+f #*f/cum_decode_flop(pos, token_num, *spe_info)\n",
    "            correct_num = correct_num + token_num\n",
    "            last_spe_decode_pos = pos\n",
    "        decode_flops = decode_flops+cum_decode_flop(last_spe_decode_pos+token_num, completion_tokens+prompt_tokens-last_spe_decode_pos-token_num, *spe_info)\n",
    "    return prefill_flops, prefix_flops, decode_flops, correct_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7b 32b\n",
      "dict_keys(['problem', 'solution', 'answer', 'subject', 'level', 'unique_id', 'responses', 'token_usages', 'prompt', 'input_conversation'])\n",
      "1534 67\n",
      "696 20\n",
      "716 125\n",
      "991 20\n",
      "1134 20\n"
     ]
    }
   ],
   "source": [
    "print(name, model)\n",
    "t=0.6\n",
    "spe_config = configs[name]\n",
    "tgt_config = configs[model]\n",
    "spe_info = spe_config.hidden_size, spe_config.intermediate_size, spe_config.num_attention_heads\n",
    "tgt_info = tgt_config.hidden_size, tgt_config.intermediate_size, tgt_config.num_attention_heads\n",
    "for k in data.keys():\n",
    "    print(data[k].keys())\n",
    "    token_usages = data[k]['token_usages'][str(t)][0]\n",
    "    correct_tokens = token_usages['correct_tokens']\n",
    "    completion_tokens = token_usages['completion_tokens']\n",
    "    prompt_tokens = token_usages['prompt_tokens']\n",
    "    decode_spe_flops, decode_tgt_flops = 0, 0\n",
    "    last_spe_decode_pos = completion_tokens\n",
    "    correct_num, token_num = 0, 0\n",
    "    print(completion_tokens, prompt_tokens )\n",
    "    for cor_t in correct_tokens:\n",
    "        pos, token_num = cor_t['pos']+prompt_tokens, cor_t['token_num']\n",
    "        print(pos, token_num )\n",
    "        decode_spe_flops = decode_spe_flops+cum_decode_flop(last_spe_decode_pos, pos-last_spe_decode_pos, *spe_info)\n",
    "        decode_tgt_flops = decode_tgt_flops+cum_decode_flop(pos, token_num, *tgt_info)\n",
    "        correct_num = correct_num + token_num\n",
    "        last_spe_decode_pos = pos\n",
    "    break\n",
    "    decode_spe_flops = decode_spe_flops+prefill_flop(correct_num+prompt_tokens, *spe_info)\n",
    "    decode_tgt_flops = decode_tgt_flops+prefill_flop(completion_tokens-correct_num, *tgt_info)\n",
    "    print(token_usages)\n",
    "    flops = decode_spe_flops+decode_tgt_flops\n",
    "    print(flops)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_info(data, name, help_model, t=0.6):\n",
    "    correct_num, correct_tokens, worng_tokens, all_time_spend = 0, 0, 0, 0\n",
    "    fix_tokens, prefill_flops, prefix_flops, decode_flops, = 0, 0, 0, 0\n",
    "    for k in data.keys():\n",
    "        # print(data[k].keys())\n",
    "        token_usages = data[k]['token_usages'][str(t)][0]\n",
    "        # time_spend = token_usages['time_spend']\n",
    "        tokens_num = token_usages['completion_tokens']\n",
    "        prefill_flop, prefix_flop, decode_flop, fix_token = get_flops(name, help_model, token_usages)\n",
    "        prefill_flops = prefill_flops + prefill_flop\n",
    "        prefix_flops = prefix_flops + prefix_flop\n",
    "        decode_flops = decode_flops + decode_flop\n",
    "        if data[k]['responses'][str(t)][0]['correctness']: \n",
    "            correct_num = correct_num+1\n",
    "            correct_tokens = correct_tokens+tokens_num\n",
    "        else:\n",
    "            worng_tokens = worng_tokens+tokens_num\n",
    "        fix_tokens = fix_tokens+fix_token\n",
    "        #  all_time_spend = all_time_spend + time_spend\n",
    "    all_num = len(data.keys())\n",
    "    r = 10000000000\n",
    "    return {\n",
    "        'all_num':all_num,\n",
    "        'acc':round(correct_num/all_num, 4),\n",
    "        'correct_avg_tokens':round(correct_tokens/correct_num, 2) if correct_num != 0 else 0,\n",
    "        'worng_avg_tokens':round(worng_tokens/(all_num-correct_num), 2) if all_num-correct_num != 0 else 0,\n",
    "        'prefill_flops': round(prefill_flops/(r), 2),\n",
    "        'prefix_flops': round(prefix_flops/(r), 2),\n",
    "        'decode_flops': round(decode_flops/(r), 2),\n",
    "        't/flops': round((correct_tokens+worng_tokens)* r/(decode_flops+prefix_flops+prefill_flops), 2),\n",
    "        #  'avg_time_spend': round((correct_tokens+worng_tokens)/all_time_spend, 2),\n",
    "        'fix_tokens': round(fix_tokens/(correct_tokens+worng_tokens),2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(dict)\n",
    "\n",
    "folder_path = \"/home/wxy320/ondemand/program/speculative_thinking/analysis/1/normal\"  # 替换为你的文件夹路径\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith(\".json\")]\n",
    "for file in json_files:\n",
    "    name = file.split('_')[0].split('-')[-1].lower()\n",
    "    if name == '1.5b': name = '1b'\n",
    "    dataset = file.split('_')[1]\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        result = get_info(data, name, None)\n",
    "    results[(name,dataset)] = {\n",
    "        'normal': result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/wxy320/ondemand/program/speculative_thinking/analysis/1/speculative\"  # 替换为你的文件夹路径\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith(\".json\")]\n",
    "\n",
    "for file in json_files:\n",
    "    name, model, dataset = file.split('_')[0], file.split('_')[1].split('.')[0], file.split('_')[2]\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        result = get_info(data, name, model)\n",
    "        # print(result)\n",
    "    results[(name,dataset)][model] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(final_results):\n",
    "    import pandas as pd\n",
    "    from collections import defaultdict\n",
    "\n",
    "    # 示例数据（替换为你的数据）\n",
    "    data = final_results\n",
    "\n",
    "    # 转换数据格式\n",
    "    def convert_to_dataframe(data):\n",
    "        rows = []\n",
    "        for dataset, models in data.items():\n",
    "            for spec_model, targets in models.items():\n",
    "                for target_model, metrics in targets.items():\n",
    "                    row = {\n",
    "                        'dataset': dataset,\n",
    "                        'speculative_model': spec_model,\n",
    "                        'target_model': target_model,\n",
    "                    }\n",
    "                    row.update(metrics)\n",
    "                    rows.append(row)\n",
    "        \n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # 转换为 DataFrame\n",
    "    df = convert_to_dataframe(data)\n",
    "\n",
    "    # 保存为 CSV 文件\n",
    "    df.to_csv(\"final_result.csv\", index=False)\n",
    "\n",
    "    # 显示表格\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aime22\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 30, 'acc': 0.3, 'correct_avg_tokens': 9296.56, 'worng_avg_tokens': 21558.86, 'prefill_flops': 34.75, 'prefix_flops': 0.0, 'decode_flops': 8357.59, 't/flops': 63.92, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.3333, 'correct_avg_tokens': 7319.2, 'worng_avg_tokens': 22248.6, 'prefill_flops': 207.31, 'prefix_flops': 7048.95, 'decode_flops': 14200.16, 't/flops': 24.15, 'fix_tokens': 0.17}\n",
      "32b {'all_num': 30, 'acc': 0.2667, 'correct_avg_tokens': 7282.12, 'worng_avg_tokens': 18987.59, 'prefill_flops': 380.8, 'prefix_flops': 9737.43, 'decode_flops': 15750.35, 't/flops': 18.4, 'fix_tokens': 0.17}\n",
      "7b\n",
      "normal {'all_num': 30, 'acc': 0.5, 'correct_avg_tokens': 9178.8, 'worng_avg_tokens': 16906.67, 'prefill_flops': 171.36, 'prefix_flops': 0.0, 'decode_flops': 21454.66, 't/flops': 18.09, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.4667, 'correct_avg_tokens': 9469.93, 'worng_avg_tokens': 22208.62, 'prefill_flops': 340.02, 'prefix_flops': 6930.08, 'decode_flops': 33801.2, 't/flops': 11.88, 'fix_tokens': 0.18}\n",
      "32b {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 7540.53, 'worng_avg_tokens': 22824.08, 'prefill_flops': 513.51, 'prefix_flops': 9334.63, 'decode_flops': 32009.98, 't/flops': 10.15, 'fix_tokens': 0.18}\n",
      "14b\n",
      "normal {'all_num': 30, 'acc': 0.6, 'correct_avg_tokens': 7878.28, 'worng_avg_tokens': 22725.0, 'prefill_flops': 178.65, 'prefix_flops': 0.0, 'decode_flops': 26026.48, 't/flops': 15.82, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 7503.65, 'worng_avg_tokens': 21042.08, 'prefill_flops': 357.23, 'prefix_flops': 0.0, 'decode_flops': 41819.96, 't/flops': 9.51, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "aime23\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 30, 'acc': 0.2, 'correct_avg_tokens': 6247.33, 'worng_avg_tokens': 20482.12, 'prefill_flops': 30.84, 'prefix_flops': 0.0, 'decode_flops': 8156.49, 't/flops': 64.62, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.2333, 'correct_avg_tokens': 5394.29, 'worng_avg_tokens': 21799.65, 'prefill_flops': 183.3, 'prefix_flops': 7455.09, 'decode_flops': 15405.9, 't/flops': 23.4, 'fix_tokens': 0.19}\n",
      "32b {'all_num': 30, 'acc': 0.2, 'correct_avg_tokens': 11683.0, 'worng_avg_tokens': 20803.83, 'prefill_flops': 336.7, 'prefix_flops': 11362.81, 'decode_flops': 21434.53, 't/flops': 17.18, 'fix_tokens': 0.2}\n",
      "7b\n",
      "normal {'all_num': 30, 'acc': 0.3667, 'correct_avg_tokens': 7842.73, 'worng_avg_tokens': 17261.95, 'prefill_flops': 152.08, 'prefix_flops': 0.0, 'decode_flops': 22865.32, 't/flops': 18.0, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 7878.41, 'worng_avg_tokens': 18862.69, 'prefill_flops': 300.65, 'prefix_flops': 5343.39, 'decode_flops': 25213.01, 't/flops': 12.29, 'fix_tokens': 0.19}\n",
      "32b {'all_num': 30, 'acc': 0.4667, 'correct_avg_tokens': 7013.93, 'worng_avg_tokens': 18907.62, 'prefill_flops': 454.05, 'prefix_flops': 8796.49, 'decode_flops': 29674.9, 't/flops': 10.29, 'fix_tokens': 0.18}\n",
      "14b\n",
      "normal {'all_num': 30, 'acc': 0.5333, 'correct_avg_tokens': 7431.38, 'worng_avg_tokens': 20517.57, 'prefill_flops': 158.55, 'prefix_flops': 0.0, 'decode_flops': 26124.52, 't/flops': 15.45, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 30, 'acc': 0.6, 'correct_avg_tokens': 8543.56, 'worng_avg_tokens': 19537.5, 'prefill_flops': 317.05, 'prefix_flops': 0.0, 'decode_flops': 40458.2, 't/flops': 9.52, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "aime24\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 30, 'acc': 0.2667, 'correct_avg_tokens': 7457.25, 'worng_avg_tokens': 21669.91, 'prefill_flops': 32.48, 'prefix_flops': 0.0, 'decode_flops': 8521.88, 't/flops': 62.7, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.4333, 'correct_avg_tokens': 7791.92, 'worng_avg_tokens': 20211.35, 'prefill_flops': 193.4, 'prefix_flops': 5500.86, 'decode_flops': 11507.76, 't/flops': 25.86, 'fix_tokens': 0.18}\n",
      "32b {'all_num': 30, 'acc': 0.5, 'correct_avg_tokens': 6680.4, 'worng_avg_tokens': 17864.33, 'prefill_flops': 355.25, 'prefix_flops': 7418.25, 'decode_flops': 12035.43, 't/flops': 18.59, 'fix_tokens': 0.18}\n",
      "7b\n",
      "normal {'all_num': 30, 'acc': 0.6, 'correct_avg_tokens': 8194.17, 'worng_avg_tokens': 19959.58, 'prefill_flops': 160.19, 'prefix_flops': 0.0, 'decode_flops': 21226.71, 't/flops': 18.1, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 6437.29, 'worng_avg_tokens': 18719.31, 'prefill_flops': 317.21, 'prefix_flops': 4576.28, 'decode_flops': 23508.63, 't/flops': 12.42, 'fix_tokens': 0.18}\n",
      "32b {'all_num': 30, 'acc': 0.5667, 'correct_avg_tokens': 6002.82, 'worng_avg_tokens': 20119.69, 'prefill_flops': 479.06, 'prefix_flops': 7420.85, 'decode_flops': 26073.72, 't/flops': 10.7, 'fix_tokens': 0.17}\n",
      "14b\n",
      "normal {'all_num': 30, 'acc': 0.6667, 'correct_avg_tokens': 6988.45, 'worng_avg_tokens': 17359.2, 'prefill_flops': 167.01, 'prefix_flops': 0.0, 'decode_flops': 18224.75, 't/flops': 17.04, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 30, 'acc': 0.8, 'correct_avg_tokens': 9594.46, 'worng_avg_tokens': 14179.67, 'prefill_flops': 333.96, 'prefix_flops': 0.0, 'decode_flops': 31704.92, 't/flops': 9.84, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "gpqa\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 198, 'acc': 0.3384, 'correct_avg_tokens': 8556.21, 'worng_avg_tokens': 7597.59, 'prefill_flops': 405.62, 'prefix_flops': 0.0, 'decode_flops': 21523.41, 't/flops': 71.53, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 198, 'acc': 0.3889, 'correct_avg_tokens': 6623.31, 'worng_avg_tokens': 9095.91, 'prefill_flops': 2450.73, 'prefix_flops': 14213.13, 'decode_flops': 36142.77, 't/flops': 30.5, 'fix_tokens': 0.15}\n",
      "32b {'all_num': 198, 'acc': 0.4192, 'correct_avg_tokens': 6757.04, 'worng_avg_tokens': 8229.69, 'prefill_flops': 4501.79, 'prefix_flops': 23833.16, 'decode_flops': 45673.21, 't/flops': 20.37, 'fix_tokens': 0.17}\n",
      "7b\n",
      "normal {'all_num': 198, 'acc': 0.4545, 'correct_avg_tokens': 5301.43, 'worng_avg_tokens': 6786.46, 'prefill_flops': 2000.26, 'prefix_flops': 0.0, 'decode_flops': 58789.35, 't/flops': 19.91, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 198, 'acc': 0.4646, 'correct_avg_tokens': 4089.74, 'worng_avg_tokens': 6918.5, 'prefill_flops': 4019.61, 'prefix_flops': 12913.01, 'decode_flops': 65373.19, 't/flops': 13.48, 'fix_tokens': 0.22}\n",
      "32b {'all_num': 198, 'acc': 0.5202, 'correct_avg_tokens': 5009.54, 'worng_avg_tokens': 6974.79, 'prefill_flops': 6070.57, 'prefix_flops': 21892.91, 'decode_flops': 83773.89, 't/flops': 10.55, 'fix_tokens': 0.22}\n",
      "14b\n",
      "normal {'all_num': 198, 'acc': 0.5707, 'correct_avg_tokens': 4574.1, 'worng_avg_tokens': 7342.75, 'prefill_flops': 2085.35, 'prefix_flops': 0.0, 'decode_flops': 59518.45, 't/flops': 18.52, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 198, 'acc': 0.6162, 'correct_avg_tokens': 4481.6, 'worng_avg_tokens': 6891.96, 'prefill_flops': 4169.99, 'prefix_flops': 0.0, 'decode_flops': 101578.52, 't/flops': 10.12, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "math500\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 500, 'acc': 0.832, 'correct_avg_tokens': 3520.69, 'worng_avg_tokens': 14939.94, 'prefill_flops': 392.03, 'prefix_flops': 0.0, 'decode_flops': 34588.77, 't/flops': 77.74, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 500, 'acc': 0.89, 'correct_avg_tokens': 3511.49, 'worng_avg_tokens': 12746.58, 'prefill_flops': 2305.99, 'prefix_flops': 23467.74, 'decode_flops': 49249.07, 't/flops': 30.17, 'fix_tokens': 0.19}\n",
      "32b {'all_num': 500, 'acc': 0.894, 'correct_avg_tokens': 3563.96, 'worng_avg_tokens': 13175.55, 'prefill_flops': 4235.83, 'prefix_flops': 42320.74, 'decode_flops': 68238.31, 't/flops': 19.96, 'fix_tokens': 0.19}\n",
      "7b\n",
      "normal {'all_num': 500, 'acc': 0.928, 'correct_avg_tokens': 3245.22, 'worng_avg_tokens': 13384.03, 'prefill_flops': 1933.23, 'prefix_flops': 0.0, 'decode_flops': 95460.1, 't/flops': 20.41, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 500, 'acc': 0.924, 'correct_avg_tokens': 3406.71, 'worng_avg_tokens': 12472.05, 'prefill_flops': 3782.22, 'prefix_flops': 22520.53, 'decode_flops': 115528.15, 't/flops': 14.44, 'fix_tokens': 0.17}\n",
      "32b {'all_num': 500, 'acc': 0.93, 'correct_avg_tokens': 3271.67, 'worng_avg_tokens': 10359.26, 'prefill_flops': 5712.06, 'prefix_flops': 35319.55, 'decode_flops': 120503.38, 't/flops': 11.66, 'fix_tokens': 0.18}\n",
      "14b\n",
      "normal {'all_num': 500, 'acc': 0.938, 'correct_avg_tokens': 3161.06, 'worng_avg_tokens': 10386.29, 'prefill_flops': 2015.46, 'prefix_flops': 0.0, 'decode_flops': 91671.22, 't/flops': 19.26, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 500, 'acc': 0.928, 'correct_avg_tokens': 3109.74, 'worng_avg_tokens': 12726.53, 'prefill_flops': 4030.24, 'prefix_flops': 0.0, 'decode_flops': 180091.5, 't/flops': 10.33, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "olympiadbench\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 674, 'acc': 0.4496, 'correct_avg_tokens': 4977.9, 'worng_avg_tokens': 14496.71, 'prefill_flops': 633.64, 'prefix_flops': 0.0, 'decode_flops': 100019.12, 't/flops': 68.42, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 71, 'acc': 0.7183, 'correct_avg_tokens': 2846.47, 'worng_avg_tokens': 2347.6, 'prefill_flops': 326.67, 'prefix_flops': 1554.02, 'decode_flops': 3428.3, 't/flops': 36.19, 'fix_tokens': 0.18}\n",
      "7b\n",
      "normal {'all_num': 674, 'acc': 0.5757, 'correct_avg_tokens': 4710.14, 'worng_avg_tokens': 13684.28, 'prefill_flops': 3124.71, 'prefix_flops': 0.0, 'decode_flops': 304781.89, 't/flops': 18.65, 'fix_tokens': 0.0}\n",
      "14b {'all_num': 674, 'acc': 0.5549, 'correct_avg_tokens': 4570.17, 'worng_avg_tokens': 11799.17, 'prefill_flops': 6157.93, 'prefix_flops': 66314.36, 'decode_flops': 339390.51, 't/flops': 12.74, 'fix_tokens': 0.19}\n",
      "14b\n",
      "normal {'all_num': 674, 'acc': 0.6454, 'correct_avg_tokens': 5074.7, 'worng_avg_tokens': 11516.15, 'prefill_flops': 3257.62, 'prefix_flops': 0.0, 'decode_flops': 285028.71, 't/flops': 17.2, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 674, 'acc': 0.681, 'correct_avg_tokens': 4905.61, 'worng_avg_tokens': 11664.35, 'prefill_flops': 6514.14, 'prefix_flops': 0.0, 'decode_flops': 476435.63, 't/flops': 9.86, 'fix_tokens': 0.0}\n",
      "------------------------\n",
      "amc23\n",
      "------------------------\n",
      "14b\n",
      "normal {'all_num': 40, 'acc': 0.925, 'correct_avg_tokens': 3970.05, 'worng_avg_tokens': 25118.33, 'prefill_flops': 160.68, 'prefix_flops': 0.0, 'decode_flops': 12499.24, 't/flops': 17.56, 'fix_tokens': 0.0}\n",
      "7b\n",
      "normal {'all_num': 40, 'acc': 0.825, 'correct_avg_tokens': 4205.0, 'worng_avg_tokens': 12241.86, 'prefill_flops': 154.12, 'prefix_flops': 0.0, 'decode_flops': 11281.67, 't/flops': 19.63, 'fix_tokens': 0.0}\n",
      "32b\n",
      "normal {'all_num': 40, 'acc': 0.9, 'correct_avg_tokens': 4165.56, 'worng_avg_tokens': 19826.75, 'prefill_flops': 321.3, 'prefix_flops': 0.0, 'decode_flops': 22846.22, 't/flops': 9.9, 'fix_tokens': 0.0}\n",
      "1b\n",
      "32b {'all_num': 40, 'acc': 0.675, 'correct_avg_tokens': 4722.15, 'worng_avg_tokens': 22260.77, 'prefill_flops': 352.55, 'prefix_flops': 7165.59, 'decode_flops': 14925.62, 't/flops': 18.57, 'fix_tokens': 0.19}\n",
      "------------------------\n",
      "livecodebench\n",
      "------------------------\n",
      "7b\n",
      "14b {'all_num': 93, 'acc': 0.9355, 'correct_avg_tokens': 2063.54, 'worng_avg_tokens': 2041.17, 'prefill_flops': 2839.58, 'prefix_flops': 1684.12, 'decode_flops': 9895.85, 't/flops': 13.3, 'fix_tokens': 0.2}\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "final_results = defaultdict(dict)\n",
    "for key, r in results.items():\n",
    "    # print(key)\n",
    "    final_results[key[1]][key[0]]=r\n",
    "for d, r in final_results.items():\n",
    "    print(d)\n",
    "    print('------------------------')\n",
    "    for k, r_ in r.items():\n",
    "        print(k)\n",
    "        for k_, r_1 in r_.items():\n",
    "            print(k_, r_1)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(dict)\n",
    "\n",
    "folder_path = \"/home/wxy320/ondemand/program/speculative_thinking/analysis/instruct/normal\"  # 替换为你的文件夹路径\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith(\".json\")]\n",
    "for file in json_files:\n",
    "    name = file.split('_')[0].split('-')[-2].lower()\n",
    "    if name == '1.5b': name = '1b'\n",
    "    dataset = file.split('_')[1]\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        result = get_info(data, name, None)\n",
    "    results[(name,dataset)] = {\n",
    "        'normal': result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/wxy320/ondemand/program/speculative_thinking/analysis/instruct/speculative\"  # 替换为你的文件夹路径\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith(\".json\")]\n",
    "\n",
    "for file in json_files:\n",
    "    name, model, dataset = file.split('_')[0], file.split('_')[1].split('.')[0], file.split('_')[2]\n",
    "    if 'instruct' in name: name = name.split('-')[0]\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        result = get_info(data, name, model)\n",
    "        # print(result)\n",
    "    results[(name,dataset)][model] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aime22\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 30, 'acc': 0.0, 'correct_avg_tokens': 0, 'worng_avg_tokens': 1954.3, 'prefill_flops': 42.19, 'prefix_flops': 0.0, 'decode_flops': 828.42, 't/flops': 67.34, 'fix_tokens': 0.0}\n",
      "7b {'all_num': 30, 'acc': 0.1667, 'correct_avg_tokens': 18455.2, 'worng_avg_tokens': 14675.16, 'prefill_flops': 200.22, 'prefix_flops': 4428.0, 'decode_flops': 15974.31, 't/flops': 22.29, 'fix_tokens': 0.36}\n",
      "32b {'all_num': 30, 'acc': 0.0667, 'correct_avg_tokens': 4298.5, 'worng_avg_tokens': 16168.0, 'prefill_flops': 380.8, 'prefix_flops': 8143.86, 'decode_flops': 22877.31, 't/flops': 14.69, 'fix_tokens': 0.32}\n",
      "7b\n",
      "normal {'all_num': 30, 'acc': 0.0667, 'correct_avg_tokens': 1052.5, 'worng_avg_tokens': 1492.54, 'prefill_flops': 208.03, 'prefix_flops': 0.0, 'decode_flops': 1925.83, 't/flops': 20.57, 'fix_tokens': 0.0}\n",
      "1b {'all_num': 30, 'acc': 0.0, 'correct_avg_tokens': 0, 'worng_avg_tokens': 8559.93, 'prefill_flops': 200.22, 'prefix_flops': 2071.4, 'decode_flops': 14965.38, 't/flops': 14.9, 'fix_tokens': 0.53}\n",
      "7b {'all_num': 30, 'acc': 0.0667, 'correct_avg_tokens': 2395.0, 'worng_avg_tokens': 12974.46, 'prefill_flops': 332.94, 'prefix_flops': 5658.91, 'decode_flops': 30260.16, 't/flops': 10.15, 'fix_tokens': 0.49}\n",
      "32b {'all_num': 30, 'acc': 0.1667, 'correct_avg_tokens': 5648.6, 'worng_avg_tokens': 10664.6, 'prefill_flops': 513.51, 'prefix_flops': 7613.67, 'decode_flops': 30836.62, 't/flops': 7.57, 'fix_tokens': 0.5}\n",
      "------------------------\n",
      "aime23\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 30, 'acc': 0.0667, 'correct_avg_tokens': 510.5, 'worng_avg_tokens': 790.79, 'prefill_flops': 38.28, 'prefix_flops': 0.0, 'decode_flops': 200.64, 't/flops': 96.95, 'fix_tokens': 0.0}\n",
      "7b {'all_num': 30, 'acc': 0.0667, 'correct_avg_tokens': 2197.0, 'worng_avg_tokens': 15760.79, 'prefill_flops': 177.04, 'prefix_flops': 4484.08, 'decode_flops': 15436.77, 't/flops': 22.18, 'fix_tokens': 0.36}\n",
      "32b {'all_num': 30, 'acc': 0.0667, 'correct_avg_tokens': 16986.0, 'worng_avg_tokens': 16110.68, 'prefill_flops': 336.7, 'prefix_flops': 7940.7, 'decode_flops': 22985.73, 't/flops': 15.52, 'fix_tokens': 0.3}\n",
      "7b\n",
      "normal {'all_num': 30, 'acc': 0.0667, 'correct_avg_tokens': 589.0, 'worng_avg_tokens': 1166.79, 'prefill_flops': 188.76, 'prefix_flops': 0.0, 'decode_flops': 1429.37, 't/flops': 20.92, 'fix_tokens': 0.0}\n",
      "1b {'all_num': 30, 'acc': 0.1, 'correct_avg_tokens': 5163.0, 'worng_avg_tokens': 8796.67, 'prefill_flops': 177.04, 'prefix_flops': 2126.05, 'decode_flops': 14944.54, 't/flops': 14.67, 'fix_tokens': 0.55}\n",
      "7b {'all_num': 30, 'acc': 0.1667, 'correct_avg_tokens': 6347.0, 'worng_avg_tokens': 7013.16, 'prefill_flops': 294.39, 'prefix_flops': 2499.11, 'decode_flops': 14548.12, 't/flops': 11.94, 'fix_tokens': 0.42}\n",
      "32b {'all_num': 30, 'acc': 0.2, 'correct_avg_tokens': 3767.67, 'worng_avg_tokens': 12191.12, 'prefill_flops': 454.05, 'prefix_flops': 7570.47, 'decode_flops': 33462.13, 't/flops': 7.6, 'fix_tokens': 0.48}\n",
      "------------------------\n",
      "aime24\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 30, 'acc': 0.0667, 'correct_avg_tokens': 824.0, 'worng_avg_tokens': 2489.18, 'prefill_flops': 39.92, 'prefix_flops': 0.0, 'decode_flops': 979.39, 't/flops': 69.99, 'fix_tokens': 0.0}\n",
      "7b {'all_num': 30, 'acc': 0.0333, 'correct_avg_tokens': 8851.0, 'worng_avg_tokens': 12688.21, 'prefill_flops': 186.79, 'prefix_flops': 4054.33, 'decode_flops': 13559.85, 't/flops': 21.17, 'fix_tokens': 0.41}\n",
      "32b {'all_num': 30, 'acc': 0.1667, 'correct_avg_tokens': 7106.4, 'worng_avg_tokens': 16655.88, 'prefill_flops': 355.25, 'prefix_flops': 7970.65, 'decode_flops': 25587.34, 't/flops': 13.33, 'fix_tokens': 0.39}\n",
      "7b\n",
      "normal {'all_num': 30, 'acc': 0.1, 'correct_avg_tokens': 1065.67, 'worng_avg_tokens': 1168.19, 'prefill_flops': 196.87, 'prefix_flops': 0.0, 'decode_flops': 1477.37, 't/flops': 20.75, 'fix_tokens': 0.0}\n",
      "1b {'all_num': 30, 'acc': 0.1, 'correct_avg_tokens': 5290.0, 'worng_avg_tokens': 7295.3, 'prefill_flops': 186.79, 'prefix_flops': 1709.84, 'decode_flops': 12286.26, 't/flops': 15.01, 'fix_tokens': 0.53}\n",
      "7b {'all_num': 30, 'acc': 0.1667, 'correct_avg_tokens': 3611.8, 'worng_avg_tokens': 13922.76, 'prefill_flops': 310.6, 'prefix_flops': 4209.37, 'decode_flops': 28196.43, 't/flops': 11.19, 'fix_tokens': 0.35}\n",
      "32b {'all_num': 30, 'acc': 0.1, 'correct_avg_tokens': 2157.67, 'worng_avg_tokens': 11285.93, 'prefill_flops': 479.06, 'prefix_flops': 6456.03, 'decode_flops': 30908.41, 't/flops': 8.22, 'fix_tokens': 0.41}\n",
      "------------------------\n",
      "gpqa\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 198, 'acc': 0.2374, 'correct_avg_tokens': 930.53, 'worng_avg_tokens': 621.55, 'prefill_flops': 454.71, 'prefix_flops': 0.0, 'decode_flops': 2148.26, 't/flops': 52.86, 'fix_tokens': 0.0}\n",
      "7b {'all_num': 198, 'acc': 0.303, 'correct_avg_tokens': 9072.95, 'worng_avg_tokens': 8995.96, 'prefill_flops': 2367.06, 'prefix_flops': 11137.8, 'decode_flops': 50494.44, 't/flops': 27.9, 'fix_tokens': 0.26}\n",
      "32b {'all_num': 198, 'acc': 0.3333, 'correct_avg_tokens': 9226.94, 'worng_avg_tokens': 11136.84, 'prefill_flops': 4501.79, 'prefix_flops': 26078.61, 'decode_flops': 86368.73, 't/flops': 17.78, 'fix_tokens': 0.26}\n",
      "7b\n",
      "normal {'all_num': 198, 'acc': 0.3384, 'correct_avg_tokens': 7.9, 'worng_avg_tokens': 4.4, 'prefill_flops': 2242.32, 'prefix_flops': 0.0, 'decode_flops': 45.75, 't/flops': 0.48, 'fix_tokens': 0.0}\n",
      "1b {'all_num': 198, 'acc': 0.3182, 'correct_avg_tokens': 6179.9, 'worng_avg_tokens': 7036.27, 'prefill_flops': 2367.06, 'prefix_flops': 9931.32, 'decode_flops': 87445.22, 't/flops': 13.43, 'fix_tokens': 0.43}\n",
      "7b {'all_num': 198, 'acc': 0.4091, 'correct_avg_tokens': 4408.12, 'worng_avg_tokens': 4969.26, 'prefill_flops': 3935.98, 'prefix_flops': 11954.13, 'decode_flops': 73932.16, 't/flops': 10.45, 'fix_tokens': 0.42}\n",
      "32b {'all_num': 198, 'acc': 0.4798, 'correct_avg_tokens': 5499.71, 'worng_avg_tokens': 7716.29, 'prefill_flops': 6070.7, 'prefix_flops': 23249.84, 'decode_flops': 113855.54, 't/flops': 9.2, 'fix_tokens': 0.31}\n",
      "------------------------\n",
      "math500\n",
      "------------------------\n",
      "1b\n",
      "normal {'all_num': 500, 'acc': 0.502, 'correct_avg_tokens': 471.81, 'worng_avg_tokens': 2384.0, 'prefill_flops': 515.98, 'prefix_flops': 0.0, 'decode_flops': 10298.91, 't/flops': 65.84, 'fix_tokens': 0.0}\n",
      "32b {'all_num': 500, 'acc': 0.488, 'correct_avg_tokens': 6348.73, 'worng_avg_tokens': 9470.82, 'prefill_flops': 4235.83, 'prefix_flops': 56055.78, 'decode_flops': 178881.14, 't/flops': 16.61, 'fix_tokens': 0.3}\n",
      "7b {'all_num': 500, 'acc': 0.482, 'correct_avg_tokens': 7933.8, 'worng_avg_tokens': 9867.91, 'prefill_flops': 2227.23, 'prefix_flops': 33426.68, 'decode_flops': 136546.66, 't/flops': 25.95, 'fix_tokens': 0.29}\n",
      "7b\n",
      "normal {'all_num': 500, 'acc': 0.74, 'correct_avg_tokens': 522.16, 'worng_avg_tokens': 1599.72, 'prefill_flops': 2544.49, 'prefix_flops': 0.0, 'decode_flops': 18911.43, 't/flops': 18.7, 'fix_tokens': 0.0}\n",
      "1b {'all_num': 500, 'acc': 0.748, 'correct_avg_tokens': 1705.76, 'worng_avg_tokens': 8305.03, 'prefill_flops': 2227.23, 'prefix_flops': 10354.9, 'decode_flops': 95198.98, 't/flops': 15.63, 'fix_tokens': 0.43}\n",
      "7b {'all_num': 500, 'acc': 0.792, 'correct_avg_tokens': 1778.13, 'worng_avg_tokens': 8479.52, 'prefill_flops': 3703.45, 'prefix_flops': 19745.49, 'decode_flops': 113894.65, 't/flops': 11.55, 'fix_tokens': 0.44}\n",
      "32b {'all_num': 500, 'acc': 0.818, 'correct_avg_tokens': 1755.81, 'worng_avg_tokens': 8679.43, 'prefill_flops': 5712.06, 'prefix_flops': 31777.2, 'decode_flops': 139557.35, 't/flops': 8.52, 'fix_tokens': 0.44}\n",
      "------------------------\n",
      "olympiadbench\n",
      "------------------------\n",
      "7b\n",
      "normal {'all_num': 674, 'acc': 0.3961, 'correct_avg_tokens': 676.42, 'worng_avg_tokens': 1386.19, 'prefill_flops': 3948.69, 'prefix_flops': 0.0, 'decode_flops': 35509.98, 't/flops': 18.88, 'fix_tokens': 0.0}\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "final_results = defaultdict(dict)\n",
    "for key, r in results.items():\n",
    "    # print(key)\n",
    "    final_results[key[1]][key[0]]=r\n",
    "for d, r in final_results.items():\n",
    "    print(d)\n",
    "    print('------------------------')\n",
    "    for k, r_ in r.items():\n",
    "        print(k)\n",
    "        for k_, r_1 in r_.items():\n",
    "            print(k_, r_1)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_dataframe(final_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multio1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
