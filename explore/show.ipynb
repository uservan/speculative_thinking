{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def highlight_corrected_tokens(response, corrected_tokens, tokenizer):\n",
    "    \"\"\"\n",
    "    使用 HTML 高亮被 target model 修正的 token（红色背景）。\n",
    "    这里保证 token 级别的一一对应。\n",
    "    \"\"\"\n",
    "    # **使用 tokenizer 进行 token 级别拆分**\n",
    "    token_ids = tokenizer(response, return_tensors=\"pt\").input_ids[0].tolist()\n",
    "    tokens = [tokenizer.decode([tid]) for tid in token_ids]  # 确保 token 与 token_id 对应\n",
    "\n",
    "    highlighted_text = []\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        # 检查该位置是否在 corrected_tokens 中\n",
    "        correction = next((c for c in corrected_tokens if c[\"position\"] == i), None)\n",
    "        if correction:\n",
    "            highlighted_text.append(f'<span style=\"background-color: red; color: white;\">{correction[\"target\"]}</span>')\n",
    "        else:\n",
    "            highlighted_text.append(token)\n",
    "\n",
    "    return \" \".join(highlighted_text)\n",
    "\n",
    "def display_results(results, tokenizer):\n",
    "    \"\"\"\n",
    "    在 Notebook 中展示问题、生成的答案，并高亮被修正的 token。\n",
    "    \"\"\"\n",
    "    for item in results:\n",
    "        question = item[\"question\"]\n",
    "        generated_answer = item[\"generated_answer\"]\n",
    "        corrected_tokens = item[\"corrected_tokens\"]\n",
    "\n",
    "        highlighted_answer = highlight_corrected_tokens(generated_answer, corrected_tokens, tokenizer)\n",
    "\n",
    "        html_content = f\"\"\"\n",
    "        <div style=\"border: 1px solid #ccc; padding: 10px; margin-bottom: 10px;\">\n",
    "            <p><b>Question:</b> {question}</p>\n",
    "            <p><b>Generated Answer:</b> {highlighted_answer}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(html_content))\n",
    "\n",
    "# **加载 JSON 结果**\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "with open(\"math500_results.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# **加载 tokenizer，确保和生成时一致**\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "# **显示结果**\n",
    "display_results(results, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multio1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
