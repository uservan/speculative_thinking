{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def highlight_corrected_tokens(response, corrected_tokens, tokenizer):\n",
    "    \"\"\"\n",
    "    使用 HTML 高亮被 target model 修正的 token（红色背景）。\n",
    "    这里保证 token 级别的一一对应。\n",
    "    \"\"\"\n",
    "    # **使用 tokenizer 进行 token 级别拆分**\n",
    "    token_ids = tokenizer(response, return_tensors=\"pt\").input_ids[0].tolist()\n",
    "    tokens = [tokenizer.decode([tid]) for tid in token_ids]  # 确保 token 与 token_id 对应\n",
    "\n",
    "    highlighted_text = []\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        # 检查该位置是否在 corrected_tokens 中\n",
    "        correction = next((c for c in corrected_tokens if c[\"position\"] == i), None)\n",
    "        if correction:\n",
    "            highlighted_text.append(f'<span style=\"background-color: red; color: white;\">{correction[\"target\"]}</span>')\n",
    "        else:\n",
    "            highlighted_text.append(token)\n",
    "\n",
    "    return \" \".join(highlighted_text)\n",
    "\n",
    "def display_results(results, tokenizer):\n",
    "    \"\"\"\n",
    "    在 Notebook 中展示问题、生成的答案，并高亮被修正的 token。\n",
    "    \"\"\"\n",
    "    for item in results:\n",
    "        question = item[\"question\"]\n",
    "        generated_answer = item[\"generated_answer\"]\n",
    "        corrected_tokens = item[\"corrected_tokens\"]\n",
    "\n",
    "        highlighted_answer = highlight_corrected_tokens(generated_answer, corrected_tokens, tokenizer)\n",
    "\n",
    "        html_content = f\"\"\"\n",
    "        <div style=\"border: 1px solid #ccc; padding: 10px; margin-bottom: 10px;\">\n",
    "            <p><b>Question:</b> {question}</p>\n",
    "            <p><b>Generated Answer:</b> {highlighted_answer}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(html_content))\n",
    "\n",
    "# **加载 JSON 结果**\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "with open(\"math500_results.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# **加载 tokenizer，确保和生成时一致**\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "# **显示结果**\n",
    "display_results(results, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxy320/miniconda3/envs/multio1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import __init__\n",
    "from utils.data_utils import read_saved_results\n",
    "from utils.qwen_math_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_math_correctness(ref, generation):\n",
    "    if not find_box(generation): return False\n",
    "    answer = strip_answer_string(ref)\n",
    "    pred = extract_answer(generation)\n",
    "    pred = strip_answer_string(pred)\n",
    "    return math_equal(pred, answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_32b_path = '/home/wxy320/ondemand/program/speculative_thinking/results/MATH500_deepseek-32b_None_0.01.json'\n",
    "deepseek_1b_path = '/home/wxy320/ondemand/program/speculative_thinking/results/MATH500_deepseek-1.5b_None_0.01.json'\n",
    "\n",
    "results_32b = read_saved_results(deepseek_32b_path)\n",
    "results_1b = read_saved_results(deepseek_1b_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "\n",
    "# 目标关键词\n",
    "keywords = {\"wait\", \"hmm\", \"alternatively\"}\n",
    "\n",
    "# 存储关键词前 3 个单词\n",
    "collected_words = {keyword: Counter() for keyword in keywords}\n",
    "\n",
    "# 遍历所有结果\n",
    "for result in results_32b:\n",
    "    text = result['generated_answer'].lower()  # 直接处理原始文本\n",
    "    \n",
    "    # 以关键词进行分割\n",
    "    for keyword in keywords:\n",
    "        parts = re.split(rf'\\b{keyword}\\b', text, flags=re.IGNORECASE)  # \\b 确保匹配完整单词\n",
    "        # 遍历找到的分割点\n",
    "        for i in range(1, len(parts)):  # 从1开始，因为0是文本开头\n",
    "            before_keyword = parts[i - 1]  # 关键词前的文本\n",
    "            token_ids = tokenizer.encode(before_keyword)\n",
    "            decoded_tokens = [tokenizer.decode([t]) for t in token_ids]\n",
    "            \n",
    "            # 取最后 3 个 token 进行统计\n",
    "            for token in decoded_tokens[-2:]:\n",
    "                collected_words[keyword][token] += 1  # 统计出现次数\n",
    "\n",
    "# # **转换 Counter 为普通字典**，方便 JSON 序列化\n",
    "# collected_words_dict = {keyword: dict(counts) for keyword, counts in collected_words.items()}\n",
    "\n",
    "# # **写入 JSON 文件**\n",
    "# output_file = \"collected_tokens_1b.json\"\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(collected_words_dict, f, indent=4, ensure_ascii=False)  # `ensure_ascii=False` 处理非 ASCII 字符\n",
    "\n",
    "# print(f\"统计结果已保存至 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait :  Counter({'<｜begin▁of▁sentence｜>': 4103})\n",
      "hmm:  Counter({'<｜begin▁of▁sentence｜>': 1195})\n",
      "alternatively:  Counter({'<｜begin▁of▁sentence｜>': 1763})\n"
     ]
    }
   ],
   "source": [
    "print('wait : ',collected_words['\\n\\n'])\n",
    "print('hmm: ',collected_words['hmm'])\n",
    "print('alternatively: ', collected_words['alternatively'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储 `\\n\\n` 后 3 个 token 的统计\n",
    "collected_tokens = Counter()\n",
    "\n",
    "# 遍历所有结果\n",
    "for result in results_1b:\n",
    "    text = result['generated_answer'].strip()  # 处理原始文本\n",
    "\n",
    "    # 按 `\\n\\n` 进行分割\n",
    "    sections = re.split(r'\\n\\n+', text)  # `\\n\\n+` 允许匹配多个连续的 `\\n\\n`\n",
    "\n",
    "    # 遍历每个段落，取其后三个 token\n",
    "    for i in range(1, len(sections)):  # 从 1 开始，确保有前一段落\n",
    "        after_break = sections[i].strip()  # `\\n\\n` 后的文本\n",
    "        token_ids = tokenizer.encode(after_break, add_special_tokens=False)  # 仅编码文本部分\n",
    "        decoded_tokens = [tokenizer.decode([t]).lower() for t in token_ids]\n",
    "\n",
    "        # 取 `\\n\\n` 后的 3 个 token 并统计\n",
    "        for token in decoded_tokens[:1]:  # 取前 3 个 token\n",
    "            collected_tokens[token] += 1  # 统计出现次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sorted_tokens = dict(sorted(\n",
    "    {k: t for k, t in collected_tokens.items() if t > 100}.items(), \n",
    "    key=lambda item: item[1],  # 依据 t 进行排序\n",
    "    reverse=True  # 倒序排序\n",
    "))\n",
    "filtered_sorted_tokens\n",
    "\n",
    "# **写入 JSON 文件**\n",
    "output_file = \"collected_tokens_nn_1b.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_sorted_tokens, f, indent=4, ensure_ascii=False)  # `ensure_ascii=False` 处理非 ASCII 字符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计thoughts数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a test.',\n",
       " 'Wait,Here comes the next part.\\n\\nThis should not be split.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'This is a test.\\n\\nWait,Here comes the next part.\\n\\nThis should not be split.'.strip()  # 处理原始文本\n",
    "\n",
    "keywords = {\"wait\", \"hmm\", \"alternately\", 'yes', 'yeah'}\n",
    "\n",
    "# **按 `\\n\\n` 进行初步分割**\n",
    "sections = re.split(r'\\n\\n+', text)\n",
    "\n",
    "# **存储最终分割的部分**\n",
    "filtered_sections = []\n",
    "temp_section = \"\"\n",
    "\n",
    "for section in sections:\n",
    "    last_20_chars = section[:20].lower()  # 取后 20 个字符并转换为小写\n",
    "    # print(last_20_chars)\n",
    "    if any(keyword in last_20_chars for keyword in keywords):\n",
    "        # 如果当前 `temp_section` 不是空的，则合并存储\n",
    "        if temp_section:\n",
    "            filtered_sections.append(temp_section.strip())\n",
    "        temp_section = section+ \"\\n\\n\"\n",
    "    else:\n",
    "        # 累积无关键词的部分，等待下次匹配\n",
    "        temp_section += section + \"\\n\\n\"\n",
    "\n",
    "# **如果最后 `temp_section` 仍有内容，加入最终结果**\n",
    "if temp_section:\n",
    "    filtered_sections.append(temp_section.strip())\n",
    "filtered_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "# 目标关键词\n",
    "keywords = {\"wait\", \"hmm\", \"alternatively\", 'yes', 'yeah', '**final', 'double-check'}\n",
    "\n",
    "def segement(results_1b):\n",
    "    filtered_sections_all = []\n",
    "    for result in results_1b:\n",
    "        text = result['generated_answer'].strip()  # 处理原始文本\n",
    "\n",
    "        # **按 `\\n\\n` 进行初步分割**\n",
    "        sections = re.split(r'\\n\\n+', text)\n",
    "\n",
    "        # **存储最终分割的部分**\n",
    "        filtered_sections = []\n",
    "        temp_section = \"\"\n",
    "\n",
    "        for section in sections:\n",
    "            last_20_chars = section[:30].lower()  # 取后 20 个字符并转换为小写\n",
    "            # print(last_20_chars)\n",
    "            if any(keyword in last_20_chars for keyword in keywords):\n",
    "                # 如果当前 `temp_section` 不是空的，则合并存储\n",
    "                if temp_section:\n",
    "                    filtered_sections.append(temp_section.strip())\n",
    "                temp_section = section+ \"\\n\\n\"\n",
    "            else:\n",
    "                # 累积无关键词的部分，等待下次匹配\n",
    "                temp_section += section + \"\\n\\n\"\n",
    "\n",
    "        # **如果最后 `temp_section` 仍有内容，加入最终结果**\n",
    "        if temp_section:\n",
    "            filtered_sections.append(temp_section.strip())\n",
    "        # print(filtered_sections)\n",
    "        filtered_sections_all.append({\n",
    "            'right': check_math_correctness(result['answer'], result['generated_answer']), \n",
    "            'question': result['question'],\n",
    "            'filtered_sections':filtered_sections,\n",
    "            'num_tokens': result['num_tokens']\n",
    "        })\n",
    "        # break\n",
    "\n",
    "    return filtered_sections_all\n",
    "\n",
    "def avg_l(s):\n",
    "    return sum(s)/len(s) if len(s)>0 else 0\n",
    "\n",
    "def avg(s):\n",
    "    if len(s) == 0:\n",
    "        return 0, 0  # 避免除零错误\n",
    "    \n",
    "    mean = sum(s) / len(s)  # 计算均值\n",
    "    variance = sum((x - mean) ** 2 for x in s) / len(s)  # 计算方差（无偏估计可用 n-1）\n",
    "    std_dev = math.sqrt(variance)  # 计算标准差\n",
    "    \n",
    "    return mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'right': True,\n",
       "  'question': 'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\\\theta),$ where $r > 0$ and $0 \\\\le \\\\theta < 2 \\\\pi.$',\n",
       "  'filtered_sections': ['Okay, so I need to convert the rectangular coordinates (0, 3) to polar coordinates. Hmm, I remember that polar coordinates are represented as (r, θ), where r is the distance from the origin to the point, and θ is the angle made with the positive x-axis. \\n\\nFirst, I should recall the formulas for converting from rectangular (x, y) to polar (r, θ). I think the formulas are:\\n- r = √(x² + y²)\\n- θ = arctan(y/x)\\n\\nLet me write that down to keep track:\\nr = √(x² + y²)\\nθ = arctan(y/x)\\n\\nAlright, so given the point (0, 3), x is 0 and y is 3. Let me plug these into the formulas.\\n\\nStarting with r:\\nr = √(0² + 3²) = √(0 + 9) = √9 = 3\\n\\nSo, r is 3. That seems straightforward.\\n\\nNow, for θ:\\nθ = arctan(y/x) = arctan(3/0)',\n",
       "   \"Wait, dividing by zero is undefined. Hmm, arctan(3/0) is arctan(∞). I remember that as x approaches 0 from the positive side, y/x approaches positive infinity, and as x approaches 0 from the negative side, y/x approaches negative infinity. But since our point is (0, 3), x is 0 and y is positive, so we are in the positive y-axis direction.\\n\\nI think arctan(∞) is π/2. Because when the angle is π/2, it's straight up along the y-axis. So, θ should be π/2.\",\n",
       "   'Let me double-check that. So, when x is 0 and y is positive, the point is on the positive y-axis, which is 90 degrees or π/2 radians. That makes sense.\\n\\nSo, putting it all together, the polar coordinates should be (3, π/2).',\n",
       "   \"Wait, but just to make sure I didn't miss anything, let me visualize this. In rectangular coordinates, (0, 3) is 3 units up along the y-axis. In polar coordinates, that should be 3 units from the origin, making a 90-degree angle with the positive x-axis. Yeah, that seems right.\\n\\nI was a bit confused earlier when I saw arctan(3/0), but now I know that 3/0 is infinity, and arctan(∞) is π/2. So, θ is π/2. \\n\\nIs there another way to think about this? Maybe using the unit circle? On the unit circle, (0, 1) corresponds to π/2. So, that point is (0, 1) in polar coordinates, which is (1, π/2). But in our case, the radius is 3, so it's just scaled up by 3. So, (3, π/2) is indeed correct.\\n\\nI don't think I made any mistakes here. I converted the x and y values correctly, calculated r, and figured out the angle θ based on the position of the point. So, yeah, the polar coordinates should be (3, π/2).\",\n",
       "   '**Final Answer**\\nThe polar coordinates are \\\\boxed{(3, \\\\frac{\\\\pi}{2})}.\\n</think>\\n\\nTo convert the rectangular coordinates \\\\((0, 3)\\\\) to polar coordinates, we use the following formulas:\\n- \\\\( r = \\\\sqrt{x^2 + y^2} \\\\)\\n- \\\\( \\\\theta = \\\\arctan\\\\left(\\\\frac{y}{x}\\\\right) \\\\)\\n\\nGiven the point \\\\((0, 3)\\\\), we have \\\\( x = 0 \\\\) and \\\\( y = 3 \\\\).\\n\\nFirst, we calculate \\\\( r \\\\):\\n\\\\[\\nr = \\\\sqrt{0^2 + 3^2} = \\\\sqrt{0 + 9} = \\\\sqrt{9} = 3\\n\\\\]\\n\\nNext, we calculate \\\\( \\\\theta \\\\):\\n\\\\[\\n\\\\theta = \\\\arctan\\\\left(\\\\frac{3}{0}\\\\right)\\n\\\\]\\nSince \\\\( \\\\frac{3}{0} \\\\) is undefined and approaches infinity, we know that \\\\( \\\\arctan(\\\\infty) = \\\\frac{\\\\pi}{2} \\\\). Given that the point \\\\((0, 3)\\\\) is on the positive y-axis, the angle is \\\\( \\\\frac{\\\\pi}{2} \\\\).\\n\\nThus, the polar coordinates are \\\\((3, \\\\frac{\\\\pi}{2})\\\\).\\n\\n\\\\[\\n\\\\boxed{(3, \\\\frac{\\\\pi}{2})}\\n\\\\]'],\n",
       "  'num_tokens': 993},\n",
       " 500,\n",
       " {'right': True,\n",
       "  'question': 'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\\\theta),$ where $r > 0$ and $0 \\\\le \\\\theta < 2 \\\\pi.$',\n",
       "  'filtered_sections': [\"Okay, so I need to convert the rectangular coordinate (0, 3) to polar coordinates. Hmm, I remember that polar coordinates are represented as (r, θ), where r is the distance from the origin and θ is the angle made with the positive x-axis. Let me try to recall the formulas for the conversion.\\n\\nFirst, the formula for r is the square root of (x squared plus y squared). So, r = √(x² + y²). In this case, x is 0 and y is 3. Plugging those in, I get r = √(0² + 3²) which simplifies to √(0 + 9) = √9 = 3. Okay, so r is 3. That part seems straightforward.\\n\\nNow, for θ, I think the formula is θ = arctangent of (y over x), right? So θ = arctan(y/x). But wait, in this case, x is 0. So, arctan(3/0). Hmm, division by zero. That's undefined. I remember that when x is 0, the point lies on the y-axis, so the angle θ should be either π/2 or 3π/2 depending on the sign of y.\\n\\nSince y is positive here (y = 3), the point is on the positive y-axis. Therefore, the angle θ should be π/2 radians, which is 90 degrees. Let me confirm that. If θ is π/2, then the polar coordinates would be (3, π/2). Does that make sense?\\n\\nLet me visualize the point (0, 3) in the rectangular system. It's located three units above the origin on the y-axis. So, in polar coordinates, it should be 3 units away from the origin at an angle of π/2. Yeah, that seems correct.\",\n",
       "   \"Wait, just to make sure I didn't make a mistake. Sometimes, when dealing with arctangent, especially when x is zero, it's easy to get confused. But since the point is on the y-axis, the angle is either 90 degrees or 270 degrees. Since y is positive, it's 90 degrees, which is π/2 radians. So, I think I'm confident with θ = π/2.\\n\\nSo putting it all together, the polar coordinates are (3, π/2). Let me write that down: (3, π/2). I don't think I need to adjust anything else because r is positive, which is required, and θ is between 0 and 2π, which π/2 satisfies.\",\n",
       "   \"Just to double-check, if I convert back from polar to rectangular coordinates, does it give me (0, 3)? The conversion formulas are x = r cos θ and y = r sin θ. So, x = 3 cos(π/2) and y = 3 sin(π/2). Cos(π/2) is 0, so x is 0. Sin(π/2) is 1, so y is 3. Perfect, that brings us back to (0, 3). So, the conversion is correct.\\n\\nI don't think I missed anything here. The key was recognizing that when x is zero, the angle is either π/2 or 3π/2, and determining the correct one based on the sign of y. Since y is positive, it's π/2. If y were negative, it would be 3π/2. But in this case, it's positive, so θ is π/2.\\n\\nTherefore, the polar coordinates for (0, 3) are (3, π/2). I feel confident about this answer after going through the steps and double-checking the conversion back to rectangular coordinates.\",\n",
       "   '**Final Answer**\\nThe polar coordinates are \\\\boxed{(3, \\\\frac{\\\\pi}{2})}.\\n</think>\\n\\nTo convert the rectangular coordinate \\\\((0, 3)\\\\) to polar coordinates, we start by calculating \\\\(r\\\\) and \\\\(\\\\theta\\\\).\\n\\n1. The formula for \\\\(r\\\\) is:\\n   \\\\[\\n   r = \\\\sqrt{x^2 + y^2}\\n   \\\\]\\n   Substituting \\\\(x = 0\\\\) and \\\\(y = 3\\\\):\\n   \\\\[\\n   r = \\\\sqrt{0^2 + 3^2} = \\\\sqrt{9} = 3\\n   \\\\]\\n\\n2. The formula for \\\\(\\\\theta\\\\) is:\\n   \\\\[\\n   \\\\theta = \\\\arctan\\\\left(\\\\frac{y}{x}\\\\right)\\n   \\\\]\\n   Since \\\\(x = 0\\\\), the point lies on the y-axis. Given \\\\(y\\\\) is positive, the angle \\\\(\\\\theta\\\\) is \\\\(\\\\frac{\\\\pi}{2}\\\\).\\n\\nThus, the polar coordinates are \\\\((3, \\\\frac{\\\\pi}{2})\\\\).\\n\\nTo verify, converting back to rectangular coordinates using \\\\(x = r \\\\cos \\\\theta\\\\) and \\\\(y = r \\\\sin \\\\theta\\\\) gives:\\n   \\\\[\\n   x = 3 \\\\cos\\\\left(\\\\frac{\\\\pi}{2}\\\\right) = 0\\n   \\\\]\\n   \\\\[\\n   y = 3 \\\\sin\\\\left(\\\\frac{\\\\pi}{2}\\\\right) = 3\\n   \\\\]\\nwhich confirms the original point.\\n\\nTherefore, the polar coordinates are \\\\(\\\\boxed{(3, \\\\frac{\\\\pi}{2})}\\\\).'],\n",
       "  'num_tokens': 1151},\n",
       " 500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sections_all_1b = segement(results_1b)\n",
    "filtered_sections_all_32b = segement(results_32b)\n",
    "filtered_sections_all_1b[0], len(filtered_sections_all_1b), filtered_sections_all_32b[0], len(filtered_sections_all_32b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (19905 > 16384). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import __init__\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen2ForCausalLM\n",
    "target_model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n",
    "\n",
    "avg_s, avg_s_l,num_tokens = {'right': [[], []], 'wrong': [[], []]}, {'right': [[], []], 'wrong': [[], []]},{'right': [[], []], 'wrong': [[], []]}\n",
    "\n",
    "for s_1 in filtered_sections_all_1b:\n",
    "    key1 = 'right' if s_1['right'] else 'wrong'\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key1][0].append(len(s_1['filtered_sections']))\n",
    "   \n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_1b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_1['filtered_sections']]\n",
    "   \n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key1][0].append(avg_l(token_count_1b)) # s_1['num_tokens']/avg_s[key1][0][-1]\n",
    "    num_tokens[key1][0].append(s_1['num_tokens'])\n",
    "   \n",
    "for s_32 in filtered_sections_all_32b:\n",
    "    key32 = 'right' if s_32['right'] else 'wrong'\n",
    "\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key32][1].append(len(s_32['filtered_sections']))\n",
    "\n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_32b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_32['filtered_sections']]\n",
    "\n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key32][1].append(avg_l(token_count_32b)) # s_32['num_tokens']/avg_s[key32][1][-1]\n",
    "    num_tokens[key32][1].append(s_32['num_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of thoughts\n",
      "right: 1.5b: [5, 12, 10, 5, 24, 7, 9, 20, 6, 15, 13, 14, 8, 17, 21, 17, 7, 21, 9, 7, 20, 11, 10, 9, 39, 4, 70, 15, 6, 10, 7, 7, 10, 4, 3, 4, 3, 14, 8, 7, 11, 28, 8, 4, 2, 3, 3, 5, 29, 8, 3, 10, 15, 13, 6, 6, 38, 12, 5, 5, 37, 5, 3, 4, 22, 10, 12, 9, 6, 12, 36, 5, 5, 8, 3, 41, 5, 6, 4, 48, 6, 115, 6, 20, 11, 10, 76, 8, 5, 7, 7, 17, 3, 29, 4, 3, 8, 6, 5, 60, 3, 10, 22, 8, 6, 44, 11, 62, 16, 6, 4, 4, 3, 9, 40, 80, 71, 5, 18, 9, 10, 31, 10, 72, 22, 7, 23, 59, 132, 10, 15, 9, 9, 17, 16, 69, 64, 65, 5, 123, 5, 4, 30, 1, 12, 23, 3, 14, 51, 145, 4, 5, 13, 7, 6, 17, 46, 8, 4, 7, 23, 25, 11, 5, 4, 47, 18, 4, 19, 7, 6, 21, 4, 7, 2, 22, 13, 15, 9, 16, 4, 6, 22, 5, 16, 130, 32, 42, 4, 8, 15, 7, 5, 104, 7, 12, 9, 8, 1, 16, 48, 6, 4, 7, 4, 4, 36, 6, 3, 10, 7, 10, 5, 5, 14, 5, 10, 4, 4, 17, 11, 14, 14, 13, 13, 7, 20, 10, 8, 3, 4, 9, 5, 25, 55, 58, 12, 16, 8, 9, 8, 6, 69, 35, 7, 15, 8, 18, 8, 6, 13, 186, 27, 21, 4, 5, 30, 7, 5, 103, 5, 23, 4, 4, 20, 17, 17, 4, 10, 16, 113, 80, 4, 11, 13, 8, 5, 5, 8, 6, 7, 6, 4, 4, 10, 57, 12, 111, 39, 10, 5, 20, 5, 36, 7, 11, 15, 12, 18, 10, 13, 10, 17, 7, 16, 106, 94, 8, 4, 4, 8, 14, 66, 15, 9, 3, 19, 10, 8, 18, 7, 10, 6, 40, 19, 192, 3, 2, 14, 29, 5, 20, 1, 6, 111, 8, 6, 7, 9, 4, 4, 13, 54, 6, 9, 11, 30, 8, 4, 5, 6, 24, 5, 4, 42, 27, 32, 4, 10, 6, 9, 8, 9, 10, 10, 40, 6, 10, 9, 19, 6, 9, 5, 8, 37, 7, 8, 19, 76, 18, 18, 3, 6, 6, 41, 10, 6, 32, 9, 4, 4, 20, 6, 31, 21, 6, 21, 6, 70, 10, 9, 4, 27, 3, 35, 5, 5, 80, 26, 32], 32b: [4, 17, 5, 3, 6, 4, 12, 11, 3, 75, 35, 17, 12, 4, 6, 18, 8, 28, 12, 8, 31, 6, 4, 9, 21, 41, 4, 7, 3, 12, 4, 11, 3, 12, 8, 8, 6, 4, 40, 5, 30, 5, 4, 16, 3, 9, 8, 7, 5, 7, 3, 4, 4, 7, 3, 17, 5, 11, 9, 12, 4, 16, 5, 7, 5, 24, 23, 8, 4, 8, 3, 11, 5, 4, 7, 5, 34, 6, 38, 11, 3, 6, 7, 5, 11, 4, 12, 6, 8, 6, 4, 3, 3, 171, 22, 5, 96, 9, 4, 4, 8, 9, 8, 4, 6, 6, 3, 5, 4, 6, 16, 88, 25, 4, 4, 90, 3, 7, 3, 14, 20, 6, 10, 4, 3, 5, 43, 5, 52, 14, 4, 4, 15, 7, 5, 16, 10, 107, 6, 4, 10, 42, 63, 23, 9, 15, 9, 32, 5, 10, 8, 6, 25, 317, 8, 131, 6, 44, 3, 18, 6, 5, 9, 7, 13, 17, 8, 5, 7, 6, 7, 4, 6, 20, 3, 5, 4, 16, 11, 10, 4, 6, 3, 13, 9, 6, 20, 4, 7, 4, 17, 7, 3, 4, 6, 10, 48, 4, 4, 23, 7, 3, 7, 2, 18, 8, 7, 33, 30, 16, 6, 17, 3, 6, 9, 9, 3, 37, 3, 4, 6, 32, 5, 6, 30, 18, 5, 14, 10, 7, 6, 16, 7, 5, 20, 13, 5, 9, 4, 5, 4, 7, 4, 3, 7, 3, 3, 21, 8, 5, 7, 20, 7, 6, 11, 4, 11, 16, 3, 9, 3, 4, 8, 8, 65, 6, 3, 8, 41, 12, 5, 8, 7, 6, 13, 5, 6, 16, 24, 5, 16, 5, 26, 178, 40, 6, 5, 11, 50, 7, 4, 3, 4, 6, 8, 4, 25, 6, 10, 8, 4, 39, 9, 16, 9, 24, 5, 6, 6, 14, 24, 4, 8, 4, 9, 8, 4, 5, 5, 4, 5, 10, 3, 7, 7, 49, 7, 28, 23, 6, 8, 13, 8, 11, 16, 6, 5, 8, 7, 6, 3, 14, 13, 6, 8, 4, 16, 24, 5, 4, 7, 6, 15, 14, 7, 120, 14, 5, 6, 40, 6, 13, 8, 9, 5, 11, 6, 47, 10, 13, 2, 12, 9, 14, 3, 7, 11, 6, 16, 7, 3, 5, 10, 3, 6, 5, 8, 5, 4, 11, 31, 31, 7, 45, 5, 3, 12, 8, 5, 10, 31, 7, 11, 4, 13, 4, 6, 16, 8, 7, 9, 5, 31, 12, 5, 4, 14, 10, 11, 5, 5, 10, 5, 4, 10, 5, 7, 27, 5, 6, 7, 23, 21, 8, 7, 6, 2, 6, 9, 5, 16, 4, 10, 18, 4, 8, 17, 9, 8, 9, 31, 46, 13, 8, 15, 98, 6, 4, 79, 15, 5, 5, 33, 19, 22]\n",
      "wrong: 1.5b: [318, 7, 2, 106, 26, 390, 13, 159, 169, 29, 35, 75, 125, 94, 8, 699, 121, 107, 115, 142, 380, 13, 57, 108, 27, 100, 213, 620, 5, 6, 2, 214, 7, 43, 133, 2, 58, 31, 72, 432, 74, 17, 291, 29, 25, 178, 114, 31, 9, 86, 172, 1336, 14, 4, 20, 151, 23, 141, 4, 198, 43, 133, 119, 98, 121, 37, 11, 189, 3, 2, 233, 1, 86, 1244, 12, 131, 234, 18, 26, 477, 3, 92, 54, 171, 332, 163, 15, 181, 1, 38], 32b: [107, 96, 6, 10, 55, 86, 7, 103, 75, 1357, 208, 9, 136, 5, 55, 139, 1507, 11, 10, 32, 101, 3, 30, 72, 64, 8, 3, 7, 107, 76, 5, 101, 196, 5, 42]\n",
      "length of thoughts\n",
      "right: 1.5b: [198.4, 266.5833333333333, 208.6, 302.8, 191.41666666666666, 180.14285714285714, 249.44444444444446, 147.85, 277.8333333333333, 195.2, 247.0, 119.5, 329.0, 151.1764705882353, 242.0952380952381, 285.94117647058823, 281.2857142857143, 281.04761904761904, 269.3333333333333, 292.85714285714283, 207.55, 177.27272727272728, 210.9, 202.88888888888889, 117.7948717948718, 276.25, 95.81428571428572, 182.2, 335.3333333333333, 250.3, 215.71428571428572, 129.42857142857142, 242.7, 264.5, 267.0, 227.0, 479.3333333333333, 263.5, 247.5, 194.0, 157.45454545454547, 307.64285714285717, 271.625, 263.75, 221.5, 342.6666666666667, 389.0, 255.8, 130.51724137931035, 192.375, 1434.0, 301.6, 280.0, 459.6923076923077, 218.0, 284.6666666666667, 90.94736842105263, 258.5833333333333, 462.4, 332.6, 166.0, 242.4, 279.6666666666667, 397.5, 121.45454545454545, 153.7, 166.66666666666666, 410.44444444444446, 230.66666666666666, 172.91666666666666, 165.47222222222223, 504.8, 213.0, 180.25, 609.3333333333334, 269.8780487804878, 497.6, 171.16666666666666, 292.0, 106.41666666666667, 287.8333333333333, 126.0, 281.6666666666667, 99.25, 256.45454545454544, 188.1, 141.44736842105263, 148.375, 312.6, 234.14285714285714, 375.57142857142856, 214.11764705882354, 422.3333333333333, 102.6896551724138, 390.25, 547.0, 242.125, 293.0, 254.2, 116.95, 274.3333333333333, 200.4, 166.95454545454547, 389.875, 217.5, 271.1363636363636, 283.90909090909093, 132.46774193548387, 249.75, 333.8333333333333, 294.5, 208.75, 646.6666666666666, 163.33333333333334, 141.775, 132.875, 163.19718309859155, 309.4, 136.22222222222223, 232.33333333333334, 222.5, 271.4193548387097, 306.8, 116.69444444444444, 117.5909090909091, 289.57142857142856, 139.95652173913044, 141.25423728813558, 69.1590909090909, 229.6, 186.46666666666667, 247.77777777777777, 302.55555555555554, 146.35294117647058, 180.5625, 60.927536231884055, 144.15625, 93.4, 242.8, 131.47154471544715, 272.2, 396.25, 203.9, 512.0, 178.08333333333334, 192.30434782608697, 488.0, 198.07142857142858, 194.37254901960785, 165.60689655172413, 414.75, 439.8, 282.0769230769231, 248.85714285714286, 214.33333333333334, 172.23529411764707, 198.02173913043478, 248.75, 408.75, 276.0, 273.69565217391306, 162.4, 174.27272727272728, 390.4, 636.75, 219.06382978723406, 124.94444444444444, 441.5, 210.42105263157896, 161.42857142857142, 241.16666666666666, 177.8095238095238, 351.75, 216.14285714285714, 177.0, 157.54545454545453, 239.0, 182.8, 148.77777777777777, 208.875, 545.25, 325.8333333333333, 112.68181818181819, 446.4, 257.0, 124.95384615384616, 121.03125, 79.23809523809524, 225.5, 402.5, 162.06666666666666, 446.2857142857143, 324.8, 104.47115384615384, 202.28571428571428, 224.5, 274.3333333333333, 275.25, 827.0, 201.125, 100.22916666666667, 376.6666666666667, 628.25, 298.85714285714283, 543.0, 375.0, 106.0, 321.5, 244.33333333333334, 149.1, 236.0, 182.0, 258.6, 314.6, 170.07142857142858, 410.2, 174.9, 215.75, 272.75, 146.11764705882354, 201.27272727272728, 259.35714285714283, 171.71428571428572, 203.15384615384616, 260.7692307692308, 396.57142857142856, 155.0, 257.8, 197.625, 494.3333333333333, 195.0, 213.55555555555554, 296.2, 143.56, 106.69090909090909, 126.62068965517241, 212.41666666666666, 211.9375, 433.875, 217.33333333333334, 499.0, 227.83333333333334, 85.76811594202898, 132.74285714285713, 416.57142857142856, 146.93333333333334, 201.375, 206.94444444444446, 369.875, 204.0, 289.46153846153845, 51.53225806451613, 156.62962962962962, 207.76190476190476, 182.75, 268.8, 122.23333333333333, 349.0, 447.2, 130.14563106796118, 235.6, 153.52173913043478, 426.0, 308.75, 147.15, 138.88235294117646, 151.0, 226.75, 251.8, 158.8125, 129.49557522123894, 409.4375, 325.0, 166.1818181818182, 240.07692307692307, 207.375, 393.8, 424.2, 243.0, 225.66666666666666, 223.57142857142858, 241.5, 338.0, 542.25, 194.6, 167.7017543859649, 211.08333333333334, 112.009009009009, 327.1025641025641, 180.3, 275.4, 319.0, 400.8, 142.33333333333334, 347.42857142857144, 220.27272727272728, 316.93333333333334, 169.5, 130.11111111111111, 343.7, 454.38461538461536, 257.8, 213.11764705882354, 193.14285714285714, 209.3125, 135.41509433962264, 125.18085106382979, 283.25, 280.75, 377.0, 336.5, 232.07142857142858, 86.37878787878788, 240.86666666666667, 257.0, 387.6666666666667, 122.57894736842105, 189.4, 232.75, 142.55555555555554, 404.57142857142856, 291.3, 194.83333333333334, 187.275, 195.10526315789474, 81.66145833333333, 444.3333333333333, 203.5, 500.7857142857143, 207.10344827586206, 202.8, 117.4, 295.0, 332.1666666666667, 114.92792792792793, 337.75, 454.6666666666667, 151.0, 780.8888888888889, 299.0, 374.0, 308.84615384615387, 116.24074074074075, 287.8333333333333, 270.77777777777777, 221.9090909090909, 196.16666666666666, 407.25, 280.5, 230.2, 326.3333333333333, 224.04166666666666, 586.8, 293.75, 157.45238095238096, 233.59259259259258, 134.125, 343.25, 267.9, 223.83333333333334, 241.0, 245.375, 257.3333333333333, 189.5, 235.9, 191.625, 283.8333333333333, 212.0, 281.3333333333333, 135.3684210526316, 395.6666666666667, 206.11111111111111, 364.6, 214.75, 219.43243243243242, 224.85714285714286, 159.125, 167.3684210526316, 112.3157894736842, 196.27777777777777, 152.83333333333334, 325.3333333333333, 294.8333333333333, 486.8333333333333, 106.5609756097561, 153.3, 297.8333333333333, 175.8125, 142.66666666666666, 253.0, 322.75, 278.25, 244.0, 143.25806451612902, 349.04761904761904, 244.16666666666666, 151.52380952380952, 331.1666666666667, 148.37142857142857, 442.2, 293.22222222222223, 349.75, 152.62962962962962, 365.3333333333333, 184.4, 446.0, 456.4, 143.55, 196.84615384615384, 177.46875], 32b: [287.5, 305.5882352941176, 326.6, 361.0, 328.3333333333333, 228.5, 253.33333333333334, 197.1818181818182, 394.3333333333333, 124.6, 153.5142857142857, 299.94117647058823, 241.25, 174.25, 232.33333333333334, 266.3888888888889, 289.25, 177.03571428571428, 297.5, 115.375, 294.3225806451613, 317.1666666666667, 483.75, 326.77777777777777, 154.0952380952381, 107.0, 243.0, 191.42857142857142, 473.6666666666667, 213.16666666666666, 197.25, 285.8181818181818, 611.0, 233.5, 155.125, 193.125, 403.6666666666667, 188.25, 138.225, 270.0, 293.93333333333334, 231.4, 300.75, 285.3125, 327.6666666666667, 182.11111111111111, 358.5, 395.7142857142857, 627.6, 369.0, 329.0, 346.75, 263.75, 174.0, 486.6666666666667, 224.41176470588235, 217.8, 526.6363636363636, 401.1111111111111, 364.5833333333333, 633.0, 212.5, 273.4, 280.57142857142856, 368.2, 181.33333333333334, 125.8695652173913, 291.375, 323.25, 155.875, 469.6666666666667, 225.54545454545453, 175.0, 228.5, 535.0, 256.0, 227.8235294117647, 181.5, 96.26315789473684, 247.27272727272728, 733.0, 177.16666666666666, 157.71428571428572, 285.2, 368.90909090909093, 584.75, 190.0, 247.0, 420.0, 258.1666666666667, 330.5, 456.0, 746.3333333333334, 98.84795321637426, 292.54545454545456, 258.2, 213.47916666666666, 567.4444444444445, 269.75, 321.5, 248.25, 349.0, 343.25, 301.0, 338.8333333333333, 269.8333333333333, 793.0, 265.6, 736.5, 432.3333333333333, 273.875, 68.19318181818181, 173.88, 446.5, 297.5, 84.25555555555556, 521.6666666666666, 307.42857142857144, 909.6666666666666, 322.0, 202.5, 338.8333333333333, 151.5, 291.5, 538.0, 295.8, 164.86046511627907, 384.0, 131.0, 378.14285714285717, 447.0, 260.5, 146.2, 297.85714285714283, 263.2, 266.0625, 235.5, 167.98130841121494, 291.8333333333333, 457.25, 291.6, 149.66666666666666, 104.98412698412699, 138.82608695652175, 230.66666666666666, 331.93333333333334, 351.77777777777777, 175.21875, 302.2, 162.2, 382.625, 262.5, 173.04, 48.69716088328076, 162.25, 84.65648854961832, 476.0, 123.4090909090909, 788.0, 267.22222222222223, 307.8333333333333, 304.2, 304.55555555555554, 324.14285714285717, 252.3846153846154, 186.05882352941177, 392.625, 353.8, 304.14285714285717, 325.8333333333333, 262.7142857142857, 332.5, 394.8333333333333, 276.45, 166.0, 356.4, 392.0, 314.75, 470.90909090909093, 192.7, 292.5, 312.1666666666667, 399.0, 474.3076923076923, 377.0, 256.8333333333333, 228.75, 505.25, 226.71428571428572, 450.25, 186.47058823529412, 292.2857142857143, 501.6666666666667, 335.75, 262.8333333333333, 210.0, 139.20833333333334, 290.75, 304.5, 284.30434782608694, 337.2857142857143, 778.6666666666666, 200.0, 369.5, 274.27777777777777, 130.5, 240.28571428571428, 142.75757575757575, 204.53333333333333, 205.6875, 379.0, 167.58823529411765, 281.0, 458.6666666666667, 160.22222222222223, 376.1111111111111, 511.3333333333333, 151.67567567567568, 342.6666666666667, 489.25, 348.1666666666667, 147.59375, 322.4, 272.8333333333333, 254.83333333333334, 279.8888888888889, 226.0, 204.07142857142858, 310.8, 195.28571428571428, 327.6666666666667, 304.25, 264.42857142857144, 325.8, 160.8, 206.46153846153845, 167.0, 165.0, 301.25, 303.6, 264.75, 249.28571428571428, 417.0, 573.3333333333334, 227.28571428571428, 531.3333333333334, 369.6666666666667, 270.7142857142857, 277.25, 404.2, 235.0, 128.95, 203.57142857142858, 275.3333333333333, 278.3636363636364, 611.25, 175.27272727272728, 149.75, 413.3333333333333, 312.8888888888889, 305.3333333333333, 406.25, 233.75, 258.5, 108.56923076923077, 225.66666666666666, 321.6666666666667, 449.125, 226.8048780487805, 221.41666666666666, 580.4, 428.875, 283.7142857142857, 297.3333333333333, 319.0769230769231, 303.6, 437.5, 359.8125, 323.1666666666667, 359.2, 149.5, 241.8, 152.19230769230768, 99.82022471910112, 178.375, 415.5, 237.2, 300.8181818181818, 89.54, 246.85714285714286, 460.25, 280.3333333333333, 231.75, 253.33333333333334, 303.25, 485.0, 242.36, 205.16666666666666, 273.9, 184.375, 355.25, 146.48717948717947, 192.44444444444446, 203.5, 486.0, 292.4166666666667, 195.0, 543.0, 386.6666666666667, 261.0, 182.70833333333334, 379.0, 241.375, 409.0, 139.11111111111111, 343.25, 618.5, 302.8, 215.6, 336.5, 313.8, 133.6, 635.3333333333334, 249.0, 269.14285714285717, 126.24489795918367, 224.57142857142858, 302.9642857142857, 345.2173913043478, 397.8333333333333, 251.625, 371.38461538461536, 292.5, 242.27272727272728, 201.4375, 387.0, 298.0, 429.0, 163.28571428571428, 268.8333333333333, 706.0, 495.64285714285717, 238.69230769230768, 247.33333333333334, 172.5, 192.75, 423.25, 185.375, 545.2, 244.0, 353.0, 315.6666666666667, 157.53333333333333, 150.28571428571428, 311.14285714285717, 99.81666666666666, 224.78571428571428, 416.6, 238.0, 135.625, 286.3333333333333, 141.69230769230768, 367.625, 302.77777777777777, 192.0, 258.90909090909093, 465.3333333333333, 147.17021276595744, 153.7, 229.30769230769232, 188.5, 567.5833333333334, 219.55555555555554, 259.7857142857143, 263.0, 235.42857142857142, 214.54545454545453, 333.0, 269.1875, 390.2857142857143, 482.3333333333333, 395.0, 408.9, 259.6666666666667, 284.3333333333333, 504.8, 273.25, 283.2, 432.0, 180.27272727272728, 239.06451612903226, 172.67741935483872, 199.85714285714286, 227.84444444444443, 215.2, 518.3333333333334, 308.25, 288.625, 156.6, 435.0, 258.741935483871, 461.0, 226.27272727272728, 449.0, 210.84615384615384, 353.5, 312.1666666666667, 293.8125, 239.0, 192.0, 171.55555555555554, 349.4, 206.67741935483872, 218.58333333333334, 266.4, 399.75, 123.14285714285714, 231.8, 195.36363636363637, 301.2, 269.8, 303.2, 332.2, 447.75, 239.8, 468.8, 395.14285714285717, 127.22222222222223, 218.2, 356.6666666666667, 255.85714285714286, 172.56521739130434, 254.9047619047619, 220.0, 235.0, 603.1666666666666, 223.0, 263.1666666666667, 319.77777777777777, 435.0, 248.4375, 279.75, 230.0, 389.05555555555554, 271.0, 313.25, 291.0, 193.44444444444446, 295.5, 341.1111111111111, 113.51612903225806, 124.28260869565217, 184.07692307692307, 169.0, 238.8, 79.12244897959184, 211.33333333333334, 284.25, 130.44303797468353, 406.46666666666664, 392.4, 481.0, 240.27272727272728, 250.10526315789474, 164.5909090909091]\n",
      "wrong: 1.5b: [103.78504672897196, 78.67708333333333, 450.3333333333333, 240.9, 130.72727272727272, 380.86046511627904, 185.57142857142858, 283.18446601941747, 198.84, 24.146647015475313, 82.6826923076923, 173.0, 137.81617647058823, 478.0, 168.78181818181818, 94.56115107913669, 21.739880557398806, 419.3636363636364, 257.4, 219.4375, 131.7128712871287, 369.0, 155.9, 194.30555555555554, 112.78125, 370.25, 448.3333333333333, 286.7142857142857, 196.9626168224299, 235.77631578947367, 604.2, 241.36633663366337, 126.86734693877551, 487.6, 80.07142857142857], 32b: [103.78504672897196, 78.67708333333333, 450.3333333333333, 240.9, 130.72727272727272, 380.86046511627904, 185.57142857142858, 283.18446601941747, 198.84, 24.146647015475313, 82.6826923076923, 173.0, 137.81617647058823, 478.0, 168.78181818181818, 94.56115107913669, 21.739880557398806, 419.3636363636364, 257.4, 219.4375, 131.7128712871287, 369.0, 155.9, 194.30555555555554, 112.78125, 370.25, 448.3333333333333, 286.7142857142857, 196.9626168224299, 235.77631578947367, 604.2, 241.36633663366337, 126.86734693877551, 487.6, 80.07142857142857]\n",
      "avg num of tokens\n",
      "right: 1.5b: [993, 3200, 2087, 1515, 4649, 1262, 2246, 2958, 1669, 2929, 3215, 1674, 2634, 2571, 5085, 4862, 1971, 5904, 2425, 2051, 4156, 1951, 2110, 1827, 4595, 1107, 6708, 2737, 2014, 2504, 1511, 907, 2429, 1059, 802, 910, 1439, 3690, 1981, 1361, 1733, 8618, 2174, 1056, 444, 1029, 1168, 1281, 3787, 1541, 4303, 3018, 4201, 5977, 1314, 1711, 3457, 3107, 2313, 1664, 6146, 1213, 840, 1591, 2673, 1539, 2007, 3695, 1385, 2077, 5962, 2528, 1067, 1443, 1829, 11067, 2489, 1028, 1169, 5110, 1728, 14494, 1693, 1986, 2825, 1882, 10760, 1188, 1564, 1640, 2630, 3642, 1268, 2985, 1564, 1642, 1939, 1761, 1273, 7021, 825, 2005, 3675, 3123, 1306, 11931, 3124, 8214, 3998, 2004, 1179, 837, 1941, 1471, 5672, 10631, 11588, 1548, 2453, 2094, 2226, 8415, 3069, 8404, 2588, 2028, 3220, 8336, 9130, 2297, 2799, 2232, 2725, 2494, 2890, 4205, 9227, 6083, 1215, 16176, 1362, 1586, 6121, 513, 2139, 4425, 1465, 2774, 9919, 24017, 1660, 2201, 3668, 1744, 1288, 2929, 9112, 1992, 1636, 1935, 6297, 4061, 1921, 1956, 2548, 10301, 2251, 1767, 4002, 1133, 1448, 3738, 1408, 1518, 355, 3468, 3108, 2744, 1342, 3344, 2182, 1957, 2480, 2233, 4113, 16247, 3880, 3329, 903, 3221, 2432, 3125, 1625, 10868, 1421, 2695, 2470, 2203, 828, 3220, 4812, 2261, 2514, 2093, 2173, 1502, 3817, 1930, 734, 1492, 1653, 1827, 1294, 1575, 2384, 2052, 1750, 866, 1093, 2485, 2215, 3633, 2406, 2642, 3391, 2777, 3101, 2579, 1582, 1484, 781, 1924, 1482, 3590, 5882, 7345, 2550, 3392, 3472, 1957, 3997, 1368, 5919, 4647, 2917, 2206, 1612, 3728, 2960, 1225, 3764, 9588, 4231, 4368, 735, 1345, 3668, 2444, 2237, 13406, 1179, 3532, 1705, 1236, 2944, 2362, 2570, 908, 2519, 2543, 14635, 32768, 1301, 1831, 3122, 1661, 1970, 2122, 1945, 1359, 1566, 1453, 1355, 2170, 1947, 9560, 2534, 12449, 12761, 1804, 1378, 6381, 2005, 5126, 2433, 2424, 4756, 2036, 2347, 3438, 5908, 2579, 3624, 1353, 3351, 14357, 11770, 2267, 1124, 1509, 2693, 3250, 5702, 3614, 2314, 1166, 2330, 1895, 1864, 2567, 2833, 2914, 1170, 7500, 3708, 15680, 1334, 408, 7012, 6007, 1016, 2349, 296, 1994, 12769, 2703, 2729, 1058, 7029, 1199, 1498, 4016, 6279, 1729, 2438, 2442, 5887, 3260, 1124, 1152, 1959, 5379, 2935, 1178, 6614, 6310, 4294, 1374, 2682, 1345, 2170, 1966, 2318, 1896, 2360, 7669, 1705, 2122, 2536, 2573, 2376, 1858, 1824, 1721, 8127, 1575, 1275, 3184, 8545, 3534, 2754, 977, 1770, 2923, 4370, 1534, 1789, 5627, 1286, 1016, 1292, 5566, 1465, 4444, 7331, 1466, 3184, 1989, 10387, 4423, 2645, 1402, 4123, 1098, 6460, 2231, 2283, 11487, 5122, 5681], 32b: [1151, 5196, 1634, 1084, 1972, 915, 3041, 2173, 1185, 9347, 5374, 5100, 2897, 699, 1395, 4796, 2319, 4962, 3571, 926, 9128, 1906, 1937, 2945, 3247, 4388, 973, 1341, 1422, 2559, 793, 3145, 1834, 2803, 1242, 1547, 2423, 754, 5531, 1351, 8822, 1158, 1204, 4566, 984, 1642, 2869, 2771, 3139, 2584, 988, 1388, 1056, 1219, 1461, 3816, 1090, 5794, 3611, 4376, 2533, 3401, 1368, 1968, 1842, 4353, 2897, 2332, 1294, 1249, 1410, 2482, 876, 915, 3746, 1282, 7748, 1091, 3659, 2721, 2200, 1066, 1110, 1427, 4059, 2340, 2281, 1484, 3361, 1553, 1325, 1369, 2241, 16913, 6439, 1292, 20512, 5109, 1080, 1287, 1987, 3142, 2749, 1206, 2034, 1620, 2381, 1329, 2947, 2596, 4389, 6002, 4348, 1787, 1192, 7589, 1566, 2153, 2730, 4509, 4051, 2034, 1516, 1168, 1615, 1480, 7090, 1921, 6813, 5295, 1790, 1043, 2194, 2086, 1317, 4259, 2356, 17975, 1754, 1831, 2917, 6290, 6615, 3194, 2078, 4980, 3167, 5608, 1513, 1624, 3062, 1576, 4327, 15438, 1300, 11091, 2857, 5433, 2365, 4814, 1848, 1522, 2742, 2270, 3283, 3165, 3142, 1770, 2133, 1956, 1840, 1331, 2372, 5530, 500, 1783, 1569, 5038, 5182, 1928, 1172, 1877, 1198, 6168, 3394, 1542, 4576, 2023, 1590, 1802, 3172, 2047, 1506, 1345, 1578, 2101, 6683, 1164, 1221, 6546, 2364, 2337, 1402, 740, 4939, 1045, 1683, 4715, 6139, 3292, 2279, 2850, 844, 2753, 1443, 3386, 1535, 5613, 1029, 1958, 2090, 4724, 1613, 1639, 7646, 5039, 1132, 2858, 3114, 1368, 1968, 4870, 1853, 1630, 3222, 2685, 836, 1486, 1206, 1520, 1060, 1748, 1669, 1721, 1593, 1595, 1110, 5687, 2220, 2022, 1647, 2581, 1427, 1653, 3064, 2446, 1930, 2397, 1241, 2817, 918, 1628, 1873, 2070, 7061, 1356, 966, 3594, 9305, 2658, 2903, 3432, 1987, 1785, 4152, 1521, 2627, 5758, 7757, 1797, 2393, 1210, 3959, 17772, 7144, 2494, 1187, 3310, 4478, 1729, 1842, 842, 928, 1521, 2427, 1941, 6062, 1233, 2741, 1477, 1422, 5715, 1734, 3257, 4375, 7019, 979, 3259, 2321, 3655, 4386, 1517, 1935, 1637, 1253, 2747, 2475, 1516, 1079, 1347, 1571, 1338, 1907, 1748, 1891, 6187, 1574, 8486, 7943, 2388, 2014, 4829, 2344, 2666, 3231, 2323, 1491, 3433, 1144, 1616, 2119, 6940, 3104, 1485, 1381, 772, 6773, 4451, 2727, 977, 2472, 1895, 2366, 2105, 2179, 11984, 3148, 2084, 1429, 5426, 1719, 1843, 2942, 2726, 961, 2852, 2793, 6918, 1538, 2987, 378, 6813, 1980, 3638, 791, 1649, 2362, 1999, 4309, 2733, 1448, 1977, 4093, 780, 1710, 2525, 2187, 1418, 1731, 1985, 7412, 5355, 1405, 10254, 1078, 1557, 3700, 2310, 787, 4351, 8022, 3228, 2491, 1797, 2743, 1415, 1874, 4702, 1914, 1345, 1545, 1748, 6409, 2628, 1334, 1602, 1725, 2319, 2153, 1508, 1350, 3035, 1662, 1792, 2407, 2345, 2767, 3437, 1092, 2143, 1792, 3970, 5356, 1761, 1646, 3620, 447, 1582, 2879, 2178, 3976, 1122, 2301, 7004, 1085, 2507, 4950, 1743, 2368, 3071, 3521, 5718, 2394, 1354, 3585, 7755, 1270, 1138, 10314, 6098, 1963, 2406, 7931, 4753, 3623]\n",
      "wrong: 1.5b: [14719, 2350, 419, 32768, 3491, 32768, 2394, 14415, 19203, 5367, 7904, 11923, 9021, 32768, 1254, 32768, 24709, 21810, 29625, 8237, 32768, 1611, 5159, 9882, 5367, 11891, 32768, 30590, 2336, 1367, 579, 17010, 3601, 5938, 13872, 495, 32768, 5397, 7974, 32768, 29385, 3181, 32768, 5023, 9545, 17171, 11823, 4334, 4442, 18955, 25295, 32768, 3673, 2088, 3929, 26589, 8279, 16633, 1621, 16204, 6735, 25705, 31679, 8461, 9713, 4892, 4161, 14513, 1536, 436, 25615, 704, 11312, 32768, 3376, 23739, 32768, 3896, 9527, 32768, 1874, 5563, 7795, 19401, 32768, 32768, 2711, 8732, 601, 8453], 32b: [11106, 7554, 2703, 2412, 7193, 32768, 1303, 29171, 14922, 32768, 17199, 1558, 18748, 2392, 9284, 13145, 32768, 4615, 2575, 7027, 13307, 1108, 4678, 13991, 7219, 2964, 1346, 2008, 21080, 17927, 3022, 24379, 24876, 2440, 3364]\n"
     ]
    }
   ],
   "source": [
    "print('num of thoughts')\n",
    "print(f'right: 1.5b: {avg_s['right'][0]}, 32b: {avg_s['right'][1]}')\n",
    "print(f'wrong: 1.5b: {avg_s['wrong'][0]}, 32b: {avg_s['wrong'][1]}')\n",
    "print('length of thoughts')\n",
    "print(f'right: 1.5b: {avg_s_l['right'][0]}, 32b: {avg_s_l['right'][1]}')\n",
    "print(f'wrong: 1.5b: {avg_s_l['wrong'][1]}, 32b: {avg_s_l['wrong'][1]}')\n",
    "print('avg num of tokens')\n",
    "print(f'right: 1.5b: {num_tokens['right'][0]}, 32b: {num_tokens['right'][1]}')\n",
    "print(f'wrong: 1.5b: {num_tokens['wrong'][0]}, 32b: {num_tokens['wrong'][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg num of thoughts\n",
      "right: 1.5b: (18.90487804878049, 25.998747166996733), 32b: (13.98279569892473, 23.663313212313856)\n",
      "wrong: 1.5b: (138.3111111111111, 218.5495440623854), 32b: (138.11428571428573, 323.6392852216423)\n",
      "avg length of thoughts\n",
      "right: 1.5b: (255.4635688690364, 129.06428101599127), 32b: (295.160009790653, 128.87618247746545)\n",
      "wrong: 1.5b: (206.0119628321458, 148.19062182765992), 32b: (233.4757125271959, 144.00071867183073)\n",
      "avg num of tokens\n",
      "right: 1.5b: (3412.765853658537, 3329.6445732540105), 32b: (2964.404301075269, 2464.4364297158354)\n",
      "wrong: 1.5b: (13785.888888888889, 11578.366283187552), 32b: (11283.42857142857, 10064.738705814798)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('avg num of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s['right'][0])}, 32b: {avg(avg_s['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s['wrong'][0])}, 32b: {avg(avg_s['wrong'][1])}')\n",
    "print('avg length of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s_l['right'][0])}, 32b: {avg(avg_s_l['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s_l['wrong'][0])}, 32b: {avg(avg_s_l['wrong'][1])}')\n",
    "print('avg num of tokens')\n",
    "print(f'right: 1.5b: {avg(num_tokens['right'][0])}, 32b: {avg(num_tokens['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(num_tokens['wrong'][0])}, 32b: {avg(num_tokens['wrong'][1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 统计32b正确，1.5错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 59)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = min(len(results_32b), len(results_1b))\n",
    "results_1b_2, results_32b_2 = [],[]\n",
    "for i in range(l):\n",
    "    r_32, r_1 = results_32b[i], results_1b[i]\n",
    "    r_32_right_flag = check_math_correctness(r_32['answer'], r_32['generated_answer'])\n",
    "    r_1_right_flag = check_math_correctness(r_1['answer'], r_1['generated_answer'])\n",
    "    if r_32['question']==r_1['question'] and (r_32_right_flag and not r_1_right_flag):\n",
    "        results_1b_2.append(r_1)\n",
    "        results_32b_2.append(r_32)\n",
    "len(results_1b_2), len(results_32b_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sections_all_1b = segement(results_1b_2)\n",
    "filtered_sections_all_32b = segement(results_32b_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import __init__\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen2ForCausalLM\n",
    "target_model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n",
    "\n",
    "avg_s, avg_s_l,num_tokens = {'right': [[], []], 'wrong': [[], []]}, {'right': [[], []], 'wrong': [[], []]},{'right': [[], []], 'wrong': [[], []]}\n",
    "\n",
    "for s_1 in filtered_sections_all_1b:\n",
    "    key1 = 'right' if s_1['right'] else 'wrong'\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key1][0].append(len(s_1['filtered_sections']))\n",
    "   \n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_1b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_1['filtered_sections']]\n",
    "   \n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key1][0].append(avg_l(token_count_1b)) # s_1['num_tokens']/avg_s[key1][0][-1]\n",
    "    num_tokens[key1][0].append(s_1['num_tokens'])\n",
    "   \n",
    "for s_32 in filtered_sections_all_32b:\n",
    "    key32 = 'right' if s_32['right'] else 'wrong'\n",
    "\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key32][1].append(len(s_32['filtered_sections']))\n",
    "\n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_32b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_32['filtered_sections']]\n",
    "\n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key32][1].append(avg_l(token_count_32b)) # s_32['num_tokens']/avg_s[key32][1][-1]\n",
    "    num_tokens[key32][1].append(s_32['num_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5b wrong, 32b right\n",
      "num of thoughts\n",
      "right: 1.5b: [], 32b: [75, 17, 4, 21, 41, 40, 30, 7, 4, 34, 38, 171, 22, 96, 88, 25, 52, 15, 10, 15, 44, 16, 7, 48, 7, 7, 18, 33, 32, 30, 7, 16, 21, 7, 8, 8, 41, 6, 16, 26, 40, 16, 9, 49, 16, 120, 13, 9, 45, 10, 16, 23, 9, 17, 31, 46, 98, 6, 15]\n",
      "wrong: 1.5b: [318, 7, 2, 26, 390, 159, 169, 29, 35, 75, 125, 699, 121, 107, 142, 380, 57, 108, 27, 213, 620, 5, 2, 43, 133, 2, 31, 72, 432, 74, 29, 25, 178, 114, 31, 86, 172, 1336, 14, 20, 151, 43, 133, 98, 121, 189, 1, 1244, 234, 18, 26, 54, 171, 332, 163, 15, 181, 1, 38], 32b: []\n",
      "length of thoughts\n",
      "right: 1.5b: [], 32b: [124.6, 299.94117647058823, 174.25, 154.0952380952381, 107.0, 138.225, 293.93333333333334, 395.7142857142857, 633.0, 227.8235294117647, 96.26315789473684, 98.84795321637426, 292.54545454545456, 213.47916666666666, 68.19318181818181, 173.88, 131.0, 146.2, 291.6, 331.93333333333334, 123.4090909090909, 314.75, 226.71428571428572, 139.20833333333334, 337.2857142857143, 200.0, 274.27777777777777, 142.75757575757575, 147.59375, 254.83333333333334, 195.28571428571428, 304.25, 270.7142857142857, 235.0, 233.75, 449.125, 226.8048780487805, 297.3333333333333, 359.8125, 152.19230769230768, 178.375, 203.5, 486.0, 126.24489795918367, 201.4375, 99.81666666666666, 229.30769230769232, 219.55555555555554, 227.84444444444443, 435.0, 293.8125, 172.56521739130434, 319.77777777777777, 291.0, 113.51612903225806, 124.28260869565217, 79.12244897959184, 211.33333333333334, 406.46666666666664]\n",
      "wrong: 1.5b: [], 32b: []\n",
      "avg num of tokens\n",
      "right: 1.5b: [], 32b: [9347, 5100, 699, 3247, 4388, 5531, 8822, 2771, 2533, 7748, 3659, 16913, 6439, 20512, 6002, 4348, 6813, 2194, 2917, 4980, 5433, 5038, 1590, 6683, 2364, 1402, 4939, 4715, 4724, 7646, 1368, 4870, 5687, 1647, 1873, 3594, 9305, 1785, 5758, 3959, 7144, 3257, 4375, 6187, 3231, 11984, 2987, 1980, 10254, 4351, 4702, 3970, 2879, 4950, 3521, 5718, 7755, 1270, 6098]\n",
      "wrong: 1.5b: [14719, 2350, 419, 3491, 32768, 14415, 19203, 5367, 7904, 11923, 9021, 32768, 24709, 21810, 8237, 32768, 5159, 9882, 5367, 32768, 30590, 2336, 579, 5938, 13872, 495, 5397, 7974, 32768, 29385, 5023, 9545, 17171, 11823, 4334, 18955, 25295, 32768, 3673, 3929, 26589, 6735, 25705, 8461, 9713, 14513, 704, 32768, 32768, 3896, 9527, 7795, 19401, 32768, 32768, 2711, 8732, 601, 8453], 32b: []\n"
     ]
    }
   ],
   "source": [
    "print('1.5b wrong, 32b right')\n",
    "print('num of thoughts')\n",
    "print(f'right: 1.5b: {avg_s['right'][0]}, 32b: {avg_s['right'][1]}')\n",
    "print(f'wrong: 1.5b: {avg_s['wrong'][0]}, 32b: {avg_s['wrong'][1]}')\n",
    "print('length of thoughts')\n",
    "print(f'right: 1.5b: {avg_s_l['right'][0]}, 32b: {avg_s_l['right'][1]}')\n",
    "print(f'wrong: 1.5b: {avg_s_l['wrong'][1]}, 32b: {avg_s_l['wrong'][1]}')\n",
    "print('avg num of tokens')\n",
    "print(f'right: 1.5b: {num_tokens['right'][0]}, 32b: {num_tokens['right'][1]}')\n",
    "print(f'wrong: 1.5b: {num_tokens['wrong'][0]}, 32b: {num_tokens['wrong'][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5b wrong, 32b right\n",
      "avg num of thoughts\n",
      "right: 1.5b: (0, 0), 32b: (30.35593220338983, 30.926793118679036)\n",
      "wrong: 1.5b: (166.45762711864407, 254.364300476858), 32b: (0, 0)\n",
      "avg length of thoughts\n",
      "right: 1.5b: (0, 0), 32b: (232.14544287280705, 110.4314979477617)\n",
      "wrong: 1.5b: (176.5181525129746, 129.39334715042693), 32b: (0, 0)\n",
      "avg num of tokens\n",
      "right: 1.5b: (0, 0), 32b: (5185.6949152542375, 3488.88192597055)\n",
      "wrong: 1.5b: (14262.813559322034, 11184.377255455867), 32b: (0, 0)\n"
     ]
    }
   ],
   "source": [
    "print('1.5b wrong, 32b right')\n",
    "print('avg num of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s['right'][0])}, 32b: {avg(avg_s['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s['wrong'][0])}, 32b: {avg(avg_s['wrong'][1])}')\n",
    "print('avg length of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s_l['right'][0])}, 32b: {avg(avg_s_l['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s_l['wrong'][0])}, 32b: {avg(avg_s_l['wrong'][1])}')\n",
    "print('avg num of tokens')\n",
    "print(f'right: 1.5b: {avg(num_tokens['right'][0])}, 32b: {avg(num_tokens['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(num_tokens['wrong'][0])}, 32b: {avg(num_tokens['wrong'][1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计1.5b 正确，32b错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = min(len(results_32b), len(results_1b))\n",
    "results_1b_2, results_32b_2 = [],[]\n",
    "for i in range(l):\n",
    "    r_32, r_1 = results_32b[i], results_1b[i]\n",
    "    r_32_right_flag = check_math_correctness(r_32['answer'], r_32['generated_answer'])\n",
    "    r_1_right_flag = check_math_correctness(r_1['answer'], r_1['generated_answer'])\n",
    "    if r_32['question']==r_1['question'] and (not r_32_right_flag and r_1_right_flag):\n",
    "        results_1b_2.append(r_1)\n",
    "        results_32b_2.append(r_32)\n",
    "len(results_1b_2), len(results_32b_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sections_all_1b = segement(results_1b_2)\n",
    "filtered_sections_all_32b = segement(results_32b_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import __init__\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen2ForCausalLM\n",
    "target_model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n",
    "\n",
    "avg_s, avg_s_l,num_tokens = {'right': [[], []], 'wrong': [[], []]}, {'right': [[], []], 'wrong': [[], []]},{'right': [[], []], 'wrong': [[], []]}\n",
    "\n",
    "for s_1 in filtered_sections_all_1b:\n",
    "    key1 = 'right' if s_1['right'] else 'wrong'\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key1][0].append(len(s_1['filtered_sections']))\n",
    "   \n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_1b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_1['filtered_sections']]\n",
    "   \n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key1][0].append(avg_l(token_count_1b)) # s_1['num_tokens']/avg_s[key1][0][-1]\n",
    "    num_tokens[key1][0].append(s_1['num_tokens'])\n",
    "   \n",
    "for s_32 in filtered_sections_all_32b:\n",
    "    key32 = 'right' if s_32['right'] else 'wrong'\n",
    "\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key32][1].append(len(s_32['filtered_sections']))\n",
    "\n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_32b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_32['filtered_sections']]\n",
    "\n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key32][1].append(avg_l(token_count_32b)) # s_32['num_tokens']/avg_s[key32][1][-1]\n",
    "    num_tokens[key32][1].append(s_32['num_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5b right, 32b wrong\n",
      "num of thoughts\n",
      "right: 1.5b: [70, 37, 115, 44], 32b: []\n",
      "wrong: 1.5b: [], 32b: [96, 10, 55, 75]\n",
      "length of thoughts\n",
      "right: 1.5b: [95.81428571428572, 166.0, 126.0, 271.1363636363636], 32b: []\n",
      "wrong: 1.5b: [78.67708333333333, 240.9, 130.72727272727272, 198.84], 32b: [78.67708333333333, 240.9, 130.72727272727272, 198.84]\n",
      "avg num of tokens\n",
      "right: 1.5b: [6708, 6146, 14494, 11931], 32b: []\n",
      "wrong: 1.5b: [], 32b: [7554, 2412, 7193, 14922]\n"
     ]
    }
   ],
   "source": [
    "print('1.5b right, 32b wrong')\n",
    "print('num of thoughts')\n",
    "print(f'right: 1.5b: {avg_s['right'][0]}, 32b: {avg_s['right'][1]}')\n",
    "print(f'wrong: 1.5b: {avg_s['wrong'][0]}, 32b: {avg_s['wrong'][1]}')\n",
    "print('length of thoughts')\n",
    "print(f'right: 1.5b: {avg_s_l['right'][0]}, 32b: {avg_s_l['right'][1]}')\n",
    "print(f'wrong: 1.5b: {avg_s_l['wrong'][1]}, 32b: {avg_s_l['wrong'][1]}')\n",
    "print('avg num of tokens')\n",
    "print(f'right: 1.5b: {num_tokens['right'][0]}, 32b: {num_tokens['right'][1]}')\n",
    "print(f'wrong: 1.5b: {num_tokens['wrong'][0]}, 32b: {num_tokens['wrong'][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5b wrong, 32b right\n",
      "avg num of thoughts\n",
      "right: 1.5b: (66.5, 30.581857366746057), 32b: (0, 0)\n",
      "wrong: 1.5b: (0, 0), 32b: (59.0, 31.788362650504666)\n",
      "avg length of thoughts\n",
      "right: 1.5b: (164.73766233766233, 66.28219116583763), 32b: (0, 0)\n",
      "wrong: 1.5b: (0, 0), 32b: (162.2860890151515, 62.25504020803516)\n",
      "avg num of tokens\n",
      "right: 1.5b: (9819.75, 3517.2935884711133), 32b: (0, 0)\n",
      "wrong: 1.5b: (0, 0), 32b: (8020.25, 4471.810392615053)\n"
     ]
    }
   ],
   "source": [
    "print('1.5b wrong, 32b right')\n",
    "print('avg num of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s['right'][0])}, 32b: {avg(avg_s['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s['wrong'][0])}, 32b: {avg(avg_s['wrong'][1])}')\n",
    "print('avg length of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s_l['right'][0])}, 32b: {avg(avg_s_l['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s_l['wrong'][0])}, 32b: {avg(avg_s_l['wrong'][1])}')\n",
    "print('avg num of tokens')\n",
    "print(f'right: 1.5b: {avg(num_tokens['right'][0])}, 32b: {avg(num_tokens['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(num_tokens['wrong'][0])}, 32b: {avg(num_tokens['wrong'][1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计1.5b错误，32b错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 31)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = min(len(results_32b), len(results_1b))\n",
    "results_1b_2, results_32b_2 = [],[]\n",
    "for i in range(l):\n",
    "    r_32, r_1 = results_32b[i], results_1b[i]\n",
    "    r_32_right_flag = check_math_correctness(r_32['answer'], r_32['generated_answer'])\n",
    "    r_1_right_flag = check_math_correctness(r_1['answer'], r_1['generated_answer'])\n",
    "    if r_32['question']==r_1['question'] and (not r_32_right_flag and not r_1_right_flag):\n",
    "        results_1b_2.append(r_1)\n",
    "        results_32b_2.append(r_32)\n",
    "len(results_1b_2), len(results_32b_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sections_all_1b = segement(results_1b_2)\n",
    "filtered_sections_all_32b = segement(results_32b_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (19905 > 16384). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import __init__\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen2ForCausalLM\n",
    "target_model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n",
    "\n",
    "avg_s, avg_s_l,num_tokens = {'right': [[], []], 'wrong': [[], []]}, {'right': [[], []], 'wrong': [[], []]},{'right': [[], []], 'wrong': [[], []]}\n",
    "\n",
    "for s_1 in filtered_sections_all_1b:\n",
    "    key1 = 'right' if s_1['right'] else 'wrong'\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key1][0].append(len(s_1['filtered_sections']))\n",
    "   \n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_1b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_1['filtered_sections']]\n",
    "   \n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key1][0].append(avg_l(token_count_1b)) # s_1['num_tokens']/avg_s[key1][0][-1]\n",
    "    num_tokens[key1][0].append(s_1['num_tokens'])\n",
    "   \n",
    "for s_32 in filtered_sections_all_32b:\n",
    "    key32 = 'right' if s_32['right'] else 'wrong'\n",
    "\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key32][1].append(len(s_32['filtered_sections']))\n",
    "\n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_32b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_32['filtered_sections']]\n",
    "\n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key32][1].append(avg_l(token_count_32b)) # s_32['num_tokens']/avg_s[key32][1][-1]\n",
    "    num_tokens[key32][1].append(s_32['num_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of thoughts\n",
      "right: 1.5b: [], 32b: []\n",
      "wrong: 1.5b: [106, 13, 94, 8, 115, 13, 100, 6, 214, 7, 58, 17, 291, 9, 4, 23, 141, 4, 198, 119, 37, 11, 3, 2, 233, 86, 12, 131, 477, 3, 92], 32b: [107, 6, 86, 7, 103, 1357, 208, 9, 136, 5, 55, 139, 1507, 11, 10, 32, 101, 3, 30, 72, 64, 8, 3, 7, 107, 76, 5, 101, 196, 5, 42]\n",
      "length of thoughts\n",
      "right: 1.5b: [], 32b: []\n",
      "wrong: 1.5b: [103.78504672897196, 450.3333333333333, 380.86046511627904, 185.57142857142858, 283.18446601941747, 24.146647015475313, 82.6826923076923, 173.0, 137.81617647058823, 478.0, 168.78181818181818, 94.56115107913669, 21.739880557398806, 419.3636363636364, 257.4, 219.4375, 131.7128712871287, 369.0, 155.9, 194.30555555555554, 112.78125, 370.25, 448.3333333333333, 286.7142857142857, 196.9626168224299, 235.77631578947367, 604.2, 241.36633663366337, 126.86734693877551, 487.6, 80.07142857142857], 32b: [103.78504672897196, 450.3333333333333, 380.86046511627904, 185.57142857142858, 283.18446601941747, 24.146647015475313, 82.6826923076923, 173.0, 137.81617647058823, 478.0, 168.78181818181818, 94.56115107913669, 21.739880557398806, 419.3636363636364, 257.4, 219.4375, 131.7128712871287, 369.0, 155.9, 194.30555555555554, 112.78125, 370.25, 448.3333333333333, 286.7142857142857, 196.9626168224299, 235.77631578947367, 604.2, 241.36633663366337, 126.86734693877551, 487.6, 80.07142857142857]\n",
      "avg num of tokens\n",
      "right: 1.5b: [], 32b: []\n",
      "wrong: 1.5b: [32768, 2394, 32768, 1254, 29625, 1611, 11891, 1367, 17010, 3601, 32768, 3181, 32768, 4442, 2088, 8279, 16633, 1621, 16204, 31679, 4892, 4161, 1536, 436, 25615, 11312, 3376, 23739, 32768, 1874, 5563], 32b: [11106, 2703, 32768, 1303, 29171, 32768, 17199, 1558, 18748, 2392, 9284, 13145, 32768, 4615, 2575, 7027, 13307, 1108, 4678, 13991, 7219, 2964, 1346, 2008, 21080, 17927, 3022, 24379, 24876, 2440, 3364]\n"
     ]
    }
   ],
   "source": [
    "print('num of thoughts')\n",
    "print(f'right: 1.5b: {avg_s['right'][0]}, 32b: {avg_s['right'][1]}')\n",
    "print(f'wrong: 1.5b: {avg_s['wrong'][0]}, 32b: {avg_s['wrong'][1]}')\n",
    "print('length of thoughts')\n",
    "print(f'right: 1.5b: {avg_s_l['right'][0]}, 32b: {avg_s_l['right'][1]}')\n",
    "print(f'wrong: 1.5b: {avg_s_l['wrong'][1]}, 32b: {avg_s_l['wrong'][1]}')\n",
    "print('avg num of tokens')\n",
    "print(f'right: 1.5b: {num_tokens['right'][0]}, 32b: {num_tokens['right'][1]}')\n",
    "print(f'wrong: 1.5b: {num_tokens['wrong'][0]}, 32b: {num_tokens['wrong'][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5b wrong, 32b wrong\n",
      "avg num of thoughts\n",
      "right: 1.5b: (0, 0), 32b: (0, 0)\n",
      "wrong: 1.5b: (84.74193548387096, 105.59813284698755), 32b: (148.32258064516128, 342.36722287124115)\n",
      "avg length of thoughts\n",
      "right: 1.5b: (0, 0), 32b: (0, 0)\n",
      "wrong: 1.5b: (262.14534376218126, 164.5740269550573), 32b: (242.66147039971776, 148.90751747128553)\n",
      "avg num of tokens\n",
      "right: 1.5b: (0, 0), 32b: (0, 0)\n",
      "wrong: 1.5b: (12878.193548387097, 12242.156584258622), 32b: (11704.483870967742, 10499.441118370394)\n"
     ]
    }
   ],
   "source": [
    "print('1.5b wrong, 32b wrong')\n",
    "print('avg num of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s['right'][0])}, 32b: {avg(avg_s['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s['wrong'][0])}, 32b: {avg(avg_s['wrong'][1])}')\n",
    "print('avg length of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s_l['right'][0])}, 32b: {avg(avg_s_l['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s_l['wrong'][0])}, 32b: {avg(avg_s_l['wrong'][1])}')\n",
    "print('avg num of tokens')\n",
    "print(f'right: 1.5b: {avg(num_tokens['right'][0])}, 32b: {avg(num_tokens['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(num_tokens['wrong'][0])}, 32b: {avg(num_tokens['wrong'][1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计1.5正确，32b正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(406, 406)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = min(len(results_32b), len(results_1b))\n",
    "results_1b_2, results_32b_2 = [],[]\n",
    "for i in range(l):\n",
    "    r_32, r_1 = results_32b[i], results_1b[i]\n",
    "    r_32_right_flag = check_math_correctness(r_32['answer'], r_32['generated_answer'])\n",
    "    r_1_right_flag = check_math_correctness(r_1['answer'], r_1['generated_answer'])\n",
    "    if r_32['question']==r_1['question'] and (r_32_right_flag and r_1_right_flag):\n",
    "        results_1b_2.append(r_1)\n",
    "        results_32b_2.append(r_32)\n",
    "len(results_1b_2), len(results_32b_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sections_all_1b = segement(results_1b_2)\n",
    "filtered_sections_all_32b = segement(results_32b_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import __init__\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen2ForCausalLM\n",
    "target_model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n",
    "\n",
    "avg_s, avg_s_l,num_tokens = {'right': [[], []], 'wrong': [[], []]}, {'right': [[], []], 'wrong': [[], []]},{'right': [[], []], 'wrong': [[], []]}\n",
    "\n",
    "for s_1 in filtered_sections_all_1b:\n",
    "    key1 = 'right' if s_1['right'] else 'wrong'\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key1][0].append(len(s_1['filtered_sections']))\n",
    "   \n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_1b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_1['filtered_sections']]\n",
    "   \n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key1][0].append(avg_l(token_count_1b)) # s_1['num_tokens']/avg_s[key1][0][-1]\n",
    "    num_tokens[key1][0].append(s_1['num_tokens'])\n",
    "   \n",
    "for s_32 in filtered_sections_all_32b:\n",
    "    key32 = 'right' if s_32['right'] else 'wrong'\n",
    "\n",
    "    # 统计 filtered_sections 的数量\n",
    "    avg_s[key32][1].append(len(s_32['filtered_sections']))\n",
    "\n",
    "    # # **使用 tokenizer 计算 token 个数**\n",
    "    token_count_32b = [len(tokenizer.encode(ss, add_special_tokens=False)) for ss in s_32['filtered_sections']]\n",
    "\n",
    "    # 统计 filtered_sections 的 token 数量\n",
    "    avg_s_l[key32][1].append(avg_l(token_count_32b)) # s_32['num_tokens']/avg_s[key32][1][-1]\n",
    "    num_tokens[key32][1].append(s_32['num_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5b right, 32b right\n",
      "avg num of thoughts\n",
      "right: 1.5b: (18.435960591133004, 25.511604380505204), 32b: (11.60344827586207, 21.39420961050354)\n",
      "wrong: 1.5b: (0, 0), 32b: (0, 0)\n",
      "avg length of thoughts\n",
      "right: 1.5b: (256.357420164912, 129.21503140275453), 32b: (304.31729907181784, 128.80065452987168)\n",
      "wrong: 1.5b: (0, 0), 32b: (0, 0)\n",
      "avg num of tokens\n",
      "right: 1.5b: (3349.6428571428573, 3265.801907125861), 32b: (2641.6059113300494, 2089.4815081194038)\n",
      "wrong: 1.5b: (0, 0), 32b: (0, 0)\n"
     ]
    }
   ],
   "source": [
    "print('1.5b right, 32b right')\n",
    "print('avg num of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s['right'][0])}, 32b: {avg(avg_s['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s['wrong'][0])}, 32b: {avg(avg_s['wrong'][1])}')\n",
    "print('avg length of thoughts')\n",
    "print(f'right: 1.5b: {avg(avg_s_l['right'][0])}, 32b: {avg(avg_s_l['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(avg_s_l['wrong'][0])}, 32b: {avg(avg_s_l['wrong'][1])}')\n",
    "print('avg num of tokens')\n",
    "print(f'right: 1.5b: {avg(num_tokens['right'][0])}, 32b: {avg(num_tokens['right'][1])}')\n",
    "print(f'wrong: 1.5b: {avg(num_tokens['wrong'][0])}, 32b: {avg(num_tokens['wrong'][1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 收集正确错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import save_all_results\n",
    "l = min(len(results_32b), len(results_1b))\n",
    "results = []\n",
    "for i in range(l):\n",
    "    r_32, r_1 = results_32b[i], results_1b[i]\n",
    "    r_32_right_flag = check_math_correctness(r_32['answer'], r_32['generated_answer'])\n",
    "    r_1_right_flag = check_math_correctness(r_1['answer'], r_1['generated_answer'])\n",
    "    if r_32['question']==r_1['question'] and ( r_32_right_flag and  r_1_right_flag):\n",
    "        # print(r_32.keys())\n",
    "        results.append({\n",
    "            'question': r_32['question'],\n",
    "            'true_answers': r_32['answer'],\n",
    "            '32b_ans': r_32['generated_answer'],\n",
    "            '32b_token_num': r_32['num_tokens'],\n",
    "            '1b_ans': r_1['generated_answer'],\n",
    "            '1b_token_num': r_1['num_tokens'],\n",
    "        })\n",
    "save_all_results('./32b_right_1b_right.jsonl', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9347 14719\n",
      "5100 2350\n",
      "699 419\n",
      "3247 3491\n",
      "4388 32768\n",
      "5531 14415\n",
      "8822 19203\n",
      "2771 5367\n",
      "2533 7904\n",
      "7748 11923\n",
      "3659 9021\n",
      "16913 32768\n",
      "6439 24709\n",
      "20512 21810\n",
      "6002 8237\n",
      "4348 32768\n",
      "6813 5159\n",
      "2194 9882\n",
      "2917 5367\n",
      "4980 32768\n",
      "5433 30590\n",
      "5038 2336\n",
      "1590 579\n",
      "6683 5938\n",
      "2364 13872\n",
      "1402 495\n",
      "4939 5397\n",
      "4715 7974\n",
      "4724 32768\n",
      "7646 29385\n",
      "1368 5023\n",
      "4870 9545\n"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(r['32b_token_num'], r['1b_token_num'])\n",
    "    r['32b_ans']\n",
    "    print(r['32b_ans'], r['1b_ans'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_results(path):\n",
    "    results = read_saved_results(path)\n",
    "    correct_num, all_time, all_tokens_num, num_8k, num_corr = 0,0,0,0,0\n",
    "    all_right_tokens_num, all_wrong_tokens_num, wrong_num = 0, 0 ,0\n",
    "    for r_i, r in enumerate(results):\n",
    "        right_flag = check_math_correctness(r['answer'], r['generated_answer'])\n",
    "        all_time = all_time + r['generation_time']\n",
    "        all_tokens_num = all_tokens_num + r['num_tokens']\n",
    "        num_corr = num_corr + len(r['corrected_tokens'])\n",
    "        if not right_flag:\n",
    "            # print('#:',r_i+1, 'ans:' ,r['answer'], 'time:' ,r['generation_time'], 'num_tokens' ,r['num_tokens'], 'num_corr', len(r['corrected_tokens']))\n",
    "            if r['num_tokens'] > 8*1024: num_8k = num_8k +1\n",
    "            wrong_num = wrong_num+1\n",
    "            all_wrong_tokens_num = all_wrong_tokens_num+r['num_tokens']\n",
    "        else:\n",
    "            correct_num = correct_num + 1\n",
    "            all_right_tokens_num = all_right_tokens_num+r['num_tokens']\n",
    "            \n",
    "    # print(len(results), all_time, all_tokens_num)\n",
    "    print(f'num: {len(results)}, acc: {correct_num/len(results)}, tokens/s: {all_tokens_num/all_time}, token_num:{all_tokens_num/len(results)}, num_8k:{num_8k}, num_corr:{num_corr/all_tokens_num}')\n",
    "    print('wrong avg tokens', all_wrong_tokens_num/wrong_num, 'wrong_num', wrong_num, 'right avg tokens' ,all_right_tokens_num/correct_num, 'correct_num', correct_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 500, acc: 0.93, tokens/s: 10.220673097870845, token_num:3546.736, num_8k:16, num_corr:0.0\n",
      "wrong avg tokens 11283.42857142857 wrong_num 35 right avg tokens 2964.404301075269 correct_num 465\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/MATH500_deepseek-32b_None_0.01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 500, acc: 0.82, tokens/s: 25.41097868231503, token_num:5279.928, num_8k:51, num_corr:0.0\n",
      "wrong avg tokens 13785.888888888889 wrong_num 90 right avg tokens 3412.765853658537 correct_num 410\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/MATH500_deepseek-1.5b_None_0.01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 500, acc: 0.866, tokens/s: 10.807558442468581, token_num:2180.852, num_8k:12, num_corr:0.0\n",
      "wrong 4010.208955223881 67 right 1897.7875288683604 433\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/old/MATH500_deepseek-32b_None.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 500, acc: 0.83, tokens/s: 13.67289027813737, token_num:2840.544, num_8k:23, num_corr:0.04682694582446179\n",
      "wrong 8288.188235294117 85 right 1724.7614457831326 415\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/old/MATH500_deepseek-32b_deepseek-1.5b_0.05.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 500, acc: 0.82, tokens/s: 15.541692500787304, token_num:2637.838, num_8k:20, num_corr:0.019069404565405457\n",
      "wrong 6534.966666666666 90 right 1782.370731707317 410\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/old/MATH500_deepseek-32b_deepseek-1.5b_0.01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 500, acc: 0.776, tokens/s: 17.559001060280558, token_num:2472.372, num_8k:24, num_corr:0.022884096729780146\n",
      "wrong 4746.232142857143 112 right 1816.0 388\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/old/MATH500_deepseek-32b_deepseek-1.5b_3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 500, acc: 0.73, tokens/s: 18.798091246518656, token_num:2366.72, num_8k:19, num_corr:0.011467347214710655\n",
      "wrong 3924.0148148148146 135 right 1790.7342465753425 365\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/old/MATH500_deepseek-32b_deepseek-1.5b_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 500, acc: 0.72, tokens/s: 26.26207647556044, token_num:3016.288, num_8k:41, num_corr:0.0\n",
      "wrong 6164.257142857143 140 right 1792.0777777777778 360\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/old/MATH500_deepseek-1.5b_None.json')\n",
    "    # print(r['generated_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 16, acc: 0.125, tokens/s: 25.48946930190531, token_num:7898.125, num_8k:4, num_corr:0.0\n",
      "wrong 8532.0 14 right 3461.0 2\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/old/AIME_deepseek-1.5b_None.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 70, acc: 0.37142857142857144, tokens/s: 14.65876794171614, token_num:12180.271428571428, num_8k:31, num_corr:0.020472215608612992\n",
      "wrong 15630.522727272728 44 right 6341.384615384615 26\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/old/AIME_deepseek-32b_deepseek-1.5b_0.01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 48, acc: 0.3541666666666667, tokens/s: 13.95262531674705, token_num:10918.604166666666, num_8k:18, num_corr:0.03904841316331262\n",
      "wrong 13549.451612903225 31 right 6121.176470588235 17\n"
     ]
    }
   ],
   "source": [
    "check_results('/home/wxy320/ondemand/program/speculative_thinking/results/old/AIME_deepseek-32b_deepseek-1.5b_0.05.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def load_kpl_files_from_folder(folder_path):\n",
    "    \"\"\"读取指定文件夹下所有.kpl文件的数据\"\"\"\n",
    "    data_dict = []  # 用字典存储 {文件名: 数据}\n",
    "    \n",
    "    # 遍历文件夹下所有文件\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.pkl'):  # 只处理 .kpl 文件\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    data = pickle.load(file)  # 反序列化\n",
    "                    data_dict.append(data)  # 存入字典\n",
    "            except Exception as e:\n",
    "                print(f\"读取文件 {file_name} 时出错: {e}\")\n",
    "    \n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = load_kpl_files_from_folder('/scratch/pbsjobs/wxy320/speculative/deepseek-32b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_probabilities, num_p = None, []\n",
    "for data in data_dict:\n",
    "    if avg_probabilities is None:\n",
    "        avg_probabilities = data['avg_probabilities']\n",
    "    else: \n",
    "        avg_probabilities = avg_probabilities + data['avg_probabilities']\n",
    "    for d in data['record_tokens']:\n",
    "        num_p.append(len(d['token']))\n",
    "# avg_probabilities = avg_probabilities/len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084\n",
      "begin ['okay', 'alright']\n",
      "[382] ['.\\n\\n'] ['4', 'now', 'hmm']\n",
      "[2055, 2160, 4710, 6771] [' So', ' Is', ' \\n\\n', ' Let'] ['app', 'so', 'let']\n",
      "[1939] ['?\\n\\n'] ['wait']\n",
      "[382] ['.\\n\\n'] ['i', 'but', 'just', 'alternatively']\n",
      "[382] ['.\\n\\n'] ['i', 'so']\n",
      "[2533] [']\\n\\n'] ['to', 'we', 'listing', 'therefore']\n"
     ]
    }
   ],
   "source": [
    "reasoning_words = ['H', 'Okay', 'Alright', ' Hmm', ' Let', ' Right', ' Alright', 'Let', ' let', ' Therefore', \n",
    "                   'Right', 'Let', 'Wait', 'Yeah', 'Alright', 'So',' Let', 'But',' But', ' So', ' Let', \n",
    "                   'Alternatively', ' However', ' Since',' now',]\n",
    "reasoning_words = ['h', 'okay', 'alright', 'hmm', 'let', 'right', 'therefore', 'wait', 'yeah', 'but', 'so', 'alternatively']\n",
    "data = data_dict[3]\n",
    "print(len(data['record_tokens']))\n",
    "for i in range(len(data['record_tokens'])):\n",
    "    d = data['record_tokens'][i]\n",
    "    # print(d['token'])\n",
    "    ts = [ t.lower() for t in d['token'] ]\n",
    "    # print(ts)\n",
    "    for t in reasoning_words:\n",
    "        if t in ts:\n",
    "            if i ==0: print('begin', ts)\n",
    "            else:\n",
    "                print(data['record_tokens'][i-1]['token_id'], data['record_tokens'][i-1]['token'], ts)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:   ,Index: 220, Probability: 1.60803, Rank: 1\n",
      "token: , ,Index: 11, Probability: 1.34385, Rank: 2\n",
      "token: 2 ,Index: 17, Probability: 1.04405, Rank: 3\n",
      "token: 1 ,Index: 16, Probability: 0.87791, Rank: 4\n",
      "token:  the ,Index: 279, Probability: 0.74955, Rank: 5\n",
      "token:  = ,Index: 284, Probability: 0.55900, Rank: 6\n",
      "token: . ,Index: 13, Probability: 0.55187, Rank: 7\n",
      "token:  is ,Index: 374, Probability: 0.54100, Rank: 8\n",
      "token: 3 ,Index: 18, Probability: 0.48716, Rank: 9\n",
      "token: 0 ,Index: 15, Probability: 0.48245, Rank: 10\n",
      "token:  \\ ,Index: 1124, Probability: 0.45517, Rank: 11\n",
      "token:  - ,Index: 481, Probability: 0.44690, Rank: 12\n",
      "token:  + ,Index: 488, Probability: 0.41471, Rank: 13\n",
      "token: .\n",
      "\n",
      " ,Index: 382, Probability: 0.37956, Rank: 14\n",
      "token: ) ,Index: 8, Probability: 0.36792, Rank: 15\n",
      "token: 4 ,Index: 19, Probability: 0.36083, Rank: 16\n",
      "token: 5 ,Index: 20, Probability: 0.32443, Rank: 17\n",
      "token:  \\( ,Index: 17767, Probability: 0.25291, Rank: 18\n",
      "token: 6 ,Index: 21, Probability: 0.25053, Rank: 19\n",
      "token:  of ,Index: 315, Probability: 0.23038, Rank: 20\n"
     ]
    }
   ],
   "source": [
    "import __init__\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B')\n",
    "# 1. 将数组展平为 (152064,)\n",
    "flat_probs = avg_probabilities.flatten()\n",
    "\n",
    "# 2. 获取从小到大的排序索引\n",
    "sorted_indices = np.argsort(flat_probs)\n",
    "\n",
    "# 3. 计算排名（从大到小，最大值排名 1）\n",
    "ranks = np.empty_like(sorted_indices)\n",
    "ranks[sorted_indices] = np.arange(1, len(flat_probs) + 1)[::-1]\n",
    "\n",
    "# 输出前 10 个数据及其排名\n",
    "for i in range(20):\n",
    "    print(f\"token: {tokenizer.decode(sorted_indices[-(i+1)])} ,Index: {sorted_indices[-(i+1)]}, Probability: {flat_probs[sorted_indices[-(i+1)]]:.5f}, Rank: {ranks[sorted_indices[-(i+1)]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 你的数值列表\n",
    "data = num_p\n",
    "\n",
    "# 创建直方图\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.histplot(num_p, bins=20, color='blue', edgecolor='black')\n",
    "\n",
    "# 获取 bin 的边界\n",
    "bins = np.histogram_bin_edges(num_p, bins=10)\n",
    "\n",
    "# 在每个 bin 顶部添加计数值，并在 x 轴标注 bin 范围\n",
    "for patch, left_edge, right_edge in zip(ax.patches, bins[:-1], bins[1:]):\n",
    "    height = patch.get_height()  # 获取柱子的高度（频数）\n",
    "    if height > 0:  # 只标注非零的 bin\n",
    "        ax.text(patch.get_x() + patch.get_width() / 2, height, f'{int(height)}', \n",
    "                ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.xlabel(\"num\", fontsize=12)\n",
    "plt.ylabel(\"count\", fontsize=12)\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_probabilities_numpy = loaded_data[\"avg_probabilities\"]\n",
    "filtered_tokens_list = loaded_data[\"filtered_tokens\"]\n",
    "\n",
    "print(avg_probabilities_numpy)\n",
    "print(filtered_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"What is the distance, in units, between the points $(2, -6)$ and $(-4, 3)$? Express your answer in simplest radical form. Please reason step by step, and put your final answer within \\\\boxed{{}}. Alright, so I have this problem here where I need to find the distance between two points on a coordinate plane. The points are (2, -6) and (-4, 3). Hmm, okay, let me think about how to approach this. I remember something about the distance formula from my geometry class. I think it involves the coordinates of the two points. \\n\\nFirst, let me recall the distance formula. If I have two points, say (x1, y1) and (x2, y2), the distance between them is calculated using the square root of [(x2 - x1) squared plus (y2 - y1) squared]. So, it's like taking the differences in the x-coordinates and y-coordinates, squaring them, adding them together, and then taking the square root of that sum. That should give me the straight-line distance between the two points. \\n\\nAlright, so applying that to the points given here: (2, -6) and (-4, 3). Let me label the points to make it clearer. Let\\u2019s say (x1, y1) is (2, -6) and (x2, y2) is (-4, 3). \\n\\nNow, I need to find the differences in the x and y coordinates. So, starting with the x-coordinates: x2 - x1 is -4 - 2. Wait, is that right? Hold on, x2 is -4 and x1 is 2. So, subtracting x1 from x2 would be -4 - 2, which is -6. Hmm, but actually, in the distance formula, it doesn't matter if it's positive or negative because when we square it, the negative will become positive. So, maybe I should just compute the absolute difference to make it easier. \\n\\nBut wait, let me double-check. The formula is (x2 - x1)^2, so if x2 is less than x1, the result will be negative, but when squared, it becomes positive. So, whether I do -4 - 2 or 2 - (-4), the squared term will be the same. Let me compute both ways to be sure.\\n\\nFirst, x2 - x1: -4 - 2 = -6. Then, y2 - y1: 3 - (-6) = 3 + 6 = 9. So, squaring these, (-6)^2 is 36, and 9^2 is 81. Then, adding them together: 36 + 81 = 117. So, the distance is the square root of 117.\\n\\nBut wait, 117 doesn't look like a perfect square. Let me see if it can be simplified. Breaking down 117: 117 divided by 9 is 13, because 9 times 13 is 117. So, 117 is 9 times 13. Therefore, sqrt(117) can be written as sqrt(9*13), which is sqrt(9)*sqrt(13), and since sqrt(9) is 3, that becomes 3*sqrt(13). \\n\\nSo, putting it all together, the distance between the two points is 3 times the square root of 13 units. Let me just recap to make sure I didn't make any mistakes. I took the coordinates, subtracted them, squared each difference, added them, and then took the square root. That seems correct.\\n\\nJust to double-check, I can visualize the points on the coordinate plane. The first point is at (2, -6), which is in the fourth quadrant, and the second point is at (-4, 3), which is in the second quadrant. The distance between them should be a straight line across the plane, not along the x or y-axis. So, the calculation seems reasonable because it's not a horizontal or vertical line; it's diagonal, which would result in a distance that's a combination of horizontal and vertical distances.\\n\\nAlternatively, I can think of the horizontal distance between them as the difference in the x-coordinates, which is 2 - (-4) = 6 units. The vertical distance is the difference in the y-coordinates, which is 3 - (-6) = 9 units. So, the horizontal distance is 6, the vertical distance is 9. Then, the distance between the points would be the hypotenuse of a right-angled triangle with legs of 6 and 9. \\n\\nUsing the Pythagorean theorem, which states that in a right-angled triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides. So, hypotenuse squared is 6^2 + 9^2 = 36 + 81 = 117. Therefore, the hypotenuse is sqrt(117), which simplifies to 3*sqrt(13). \\n\\nOkay, so both methods give me the same result. That makes me feel confident that 3*sqrt(13) is the correct distance. Just to make sure, I can also compute sqrt(117) using a calculator. Let me do that. \\n\\nCalculating sqrt(117): 117 is between 100 and 121, so sqrt(117) should be between 10 and 11. Let me see: 10.8 squared is 116.64, which is just under 117. So, sqrt(117) is approximately 10.8167. Then, 3*sqrt(13) would be approximately 3*3.6055512755, which is approximately 10.8166538265. So, that matches up with the decimal approximation of sqrt(117). \\n\\nTherefore, both the exact value and the approximate decimal value check out. So, I think I can safely conclude that the distance between the points (2, -6) and (-4, 3) is 3*sqrt(13) units.\\n\\n**Final Answer**\\nThe distance between the points is \\\\boxed{3\\\\sqrt{13}} units.\\n</think>\\n\\nTo find the distance between the points \\\\((2, -6)\\\\) and \\\\((-4, 3)\\\\), we use the distance formula. The distance formula is given by:\\n\\n\\\\[\\n\\\\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\\n\\\\]\\n\\nLabeling the points as \\\\((x_1, y_1) = (2, -6)\\\\) and \\\\((x_2, y_2) = (-4, 3)\\\\), we calculate the differences in the coordinates:\\n\\n\\\\[\\nx_2 - x_1 = -4 - 2 = -6\\n\\\\]\\n\\\\[\\ny_2 - y_1 = 3 - (-6) = 3 + 6 = 9\\n\\\\]\\n\\nNext, we square these differences:\\n\\n\\\\[\\n(-6)^2 = 36\\n\\\\]\\n\\\\[\\n9^2 = 81\\n\\\\]\\n\\nAdding these squared differences:\\n\\n\\\\[\\n36 + 81 = 117\\n\\\\]\\n\\nTaking the square root of the sum:\\n\\n\\\\[\\n\\\\sqrt{117}\\n\\\\]\\n\\nWe simplify \\\\(\\\\sqrt{117}\\\\) by noting that 117 factors into \\\\(9 \\\\times 13\\\\):\\n\\n\\\\[\\n\\\\sqrt{117} = \\\\sqrt{9 \\\\times 13} = \\\\sqrt{9} \\\\times \\\\sqrt{13} = 3\\\\sqrt{13}\\n\\\\]\\n\\nThus, the distance between the points is \\\\(\\\\boxed{3\\\\sqrt{13}}\\\\) units.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =\"Please reason step by step, and put your final answer within \\\\boxed{{}}. Let's solve the problem step by step. We need to find the value of \\\\(a_9\\\\) given that \\\\(a_{i+1} = \\\\frac{1}{1 - a_i}\\\\) and \\\\(a_3 = a_1\\\\).\\n\\nFirst, let's denote \\\\(a_1 = x\\\\). Then, we can find the values of \\\\(a_2\\\\), \\\\(a_3\\\\), and so on in terms of \\\\(x\\\\):\\n\\n1. \\\\(a_2 = \\\\frac{1}{1 - a_1} = \\\\frac{1}{1 - x}\\\\)\\n2. \\\\(a_3 = \\\\frac{1}{1 - a_2} = \\\\frac{1}{1 - \\\\frac{1}{1 - x}} = \\\\frac{1}{\\\\frac{(1 - x) - 1}{1 - x}} = \\\\frac{1}{\\\\frac{-x}{1 - x}} = \\\\frac{1 - x}{-x} = \\\\frac{x - 1}{x}\\\\)\\n3. \\\\(a_4 = \\\\frac{1}{1 - a_3} = \\\\frac{1}{1 - \\\\frac{x - 1}{x}} = \\\\frac{1}{\\\\frac{x - (x - 1)}{x}} = \\\\frac{1}{\\\\frac{1}{x}} = x\\\\)\\n\\nWe see that \\\\(a_4 = a_1\\\\). This means the sequence is periodic with a period of 3. Therefore, \\\\(a_3 = a_1\\\\), \\\\(a_4 = a_1\\\\), \\\\(a_5 = a_2\\\\), \\\\(a_6 = a_3 = a_1\\\\), and so on. So, \\\\(a_9 = a_3 = a_1 = x\\\\).\\n\\nNow, we need to find \\\\((a_9)^9\\\\). Since \\\\(a_9 = x\\\\), we have \\\\((a_9)^9 = x^9\\\\).\\n\\nTo find \\\\(x\\\\), we use the fact that \\\\(a_3 = a_1\\\\):\\n\\n\\\\[a_3 = \\\\frac{x - 1}{x} = x\\\\]\\n\\nSolving for \\\\(x\\\\):\\n\\n\\\\[\\\\frac{x - 1}{x} = x\\\\]\\n\\\\[x - 1 = x^2\\\\]\\n\\\\[x^2 - x + 1 = 0\\\\]\\n\\nThis quadratic equation has no real solutions, but we can still find \\\\(x^9\\\\) by noting that the sequence is periodic with period 3. Since \\\\(a_9 = a_3 = a_1 = x\\\\), we need to find the value of \\\\(x^9\\\\).\\n\\nSince \\\\(a_3 = a_1\\\\), we have:\\n\\n\\\\[a_3 = \\\\frac{x - 1}{x} = x\\\\]\\n\\\\[x^2 - x + 1 = 0\\\\]\\n\\nWe can use the fact that \\\\(x^3 = 1\\\\) (from the periodicity of the sequence) to find \\\\(x^9\\\\):\\n\\n\\\\[x^9 = (x^3)^3 = 1^3 = 1\\\\]\\n\\nTherefore, the final answer is \\\\(\\\\boxed{1}\\\\).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_p = s.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the distance, in units, between the points $(2, -6)$ and $(-4, 3)$? Express your answer in simplest radical form. Please reason step by step, and put your final answer within \\boxed{{}}. Alright, so I have this problem here where I need to find the distance between two points on a coordinate plane. The points are (2, -6) and (-4, 3). Hmm, okay, let me think about how to approach this. I remember something about the distance formula from my geometry class. I think it involves the coordinates of the two points. \n",
      "First, let me recall the distance formula. If I have two points, say (x1, y1) and (x2, y2), the distance between them is calculated using the square root of [(x2 - x1) squared plus (y2 - y1) squared]. So, it's like taking the differences in the x-coordinates and y-coordinates, squaring them, adding them together, and then taking the square root of that sum. That should give me the straight-line distance between the two points. \n",
      "Alright, so applying that to the points given here: (2, -6) and (-4, 3). Let me label the points to make it clearer. Let’s say (x1, y1) is (2, -6) and (x2, y2) is (-4, 3). \n",
      "Now, I need to find the differences in the x and y coordinates. So, starting with the x-coordinates: x2 - x1 is -4 - 2. Wait, is that right? Hold on, x2 is -4 and x1 is 2. So, subtracting x1 from x2 would be -4 - 2, which is -6. Hmm, but actually, in the distance formula, it doesn't matter if it's positive or negative because when we square it, the negative will become positive. So, maybe I should just compute the absolute difference to make it easier. \n",
      "But wait, let me double-check. The formula is (x2 - x1)^2, so if x2 is less than x1, the result will be negative, but when squared, it becomes positive. So, whether I do -4 - 2 or 2 - (-4), the squared term will be the same. Let me compute both ways to be sure.\n",
      "First, x2 - x1: -4 - 2 = -6. Then, y2 - y1: 3 - (-6) = 3 + 6 = 9. So, squaring these, (-6)^2 is 36, and 9^2 is 81. Then, adding them together: 36 + 81 = 117. So, the distance is the square root of 117.\n",
      "But wait, 117 doesn't look like a perfect square. Let me see if it can be simplified. Breaking down 117: 117 divided by 9 is 13, because 9 times 13 is 117. So, 117 is 9 times 13. Therefore, sqrt(117) can be written as sqrt(9*13), which is sqrt(9)*sqrt(13), and since sqrt(9) is 3, that becomes 3*sqrt(13). \n",
      "So, putting it all together, the distance between the two points is 3 times the square root of 13 units. Let me just recap to make sure I didn't make any mistakes. I took the coordinates, subtracted them, squared each difference, added them, and then took the square root. That seems correct.\n",
      "Just to double-check, I can visualize the points on the coordinate plane. The first point is at (2, -6), which is in the fourth quadrant, and the second point is at (-4, 3), which is in the second quadrant. The distance between them should be a straight line across the plane, not along the x or y-axis. So, the calculation seems reasonable because it's not a horizontal or vertical line; it's diagonal, which would result in a distance that's a combination of horizontal and vertical distances.\n",
      "Alternatively, I can think of the horizontal distance between them as the difference in the x-coordinates, which is 2 - (-4) = 6 units. The vertical distance is the difference in the y-coordinates, which is 3 - (-6) = 9 units. So, the horizontal distance is 6, the vertical distance is 9. Then, the distance between the points would be the hypotenuse of a right-angled triangle with legs of 6 and 9. \n",
      "Using the Pythagorean theorem, which states that in a right-angled triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides. So, hypotenuse squared is 6^2 + 9^2 = 36 + 81 = 117. Therefore, the hypotenuse is sqrt(117), which simplifies to 3*sqrt(13). \n",
      "Okay, so both methods give me the same result. That makes me feel confident that 3*sqrt(13) is the correct distance. Just to make sure, I can also compute sqrt(117) using a calculator. Let me do that. \n",
      "Calculating sqrt(117): 117 is between 100 and 121, so sqrt(117) should be between 10 and 11. Let me see: 10.8 squared is 116.64, which is just under 117. So, sqrt(117) is approximately 10.8167. Then, 3*sqrt(13) would be approximately 3*3.6055512755, which is approximately 10.8166538265. So, that matches up with the decimal approximation of sqrt(117). \n",
      "Therefore, both the exact value and the approximate decimal value check out. So, I think I can safely conclude that the distance between the points (2, -6) and (-4, 3) is 3*sqrt(13) units.\n",
      "**Final Answer**\n",
      "The distance between the points is \\boxed{3\\sqrt{13}} units.\n",
      "</think>\n",
      "To find the distance between the points \\((2, -6)\\) and \\((-4, 3)\\), we use the distance formula. The distance formula is given by:\n",
      "\\[\n",
      "\\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n",
      "\\]\n",
      "Labeling the points as \\((x_1, y_1) = (2, -6)\\) and \\((x_2, y_2) = (-4, 3)\\), we calculate the differences in the coordinates:\n",
      "\\[\n",
      "x_2 - x_1 = -4 - 2 = -6\n",
      "\\]\n",
      "\\[\n",
      "y_2 - y_1 = 3 - (-6) = 3 + 6 = 9\n",
      "\\]\n",
      "Next, we square these differences:\n",
      "\\[\n",
      "(-6)^2 = 36\n",
      "\\]\n",
      "\\[\n",
      "9^2 = 81\n",
      "\\]\n",
      "Adding these squared differences:\n",
      "\\[\n",
      "36 + 81 = 117\n",
      "\\]\n",
      "Taking the square root of the sum:\n",
      "\\[\n",
      "\\sqrt{117}\n",
      "\\]\n",
      "We simplify \\(\\sqrt{117}\\) by noting that 117 factors into \\(9 \\times 13\\):\n",
      "\\[\n",
      "\\sqrt{117} = \\sqrt{9 \\times 13} = \\sqrt{9} \\times \\sqrt{13} = 3\\sqrt{13}\n",
      "\\]\n",
      "Thus, the distance between the points is \\(\\boxed{3\\sqrt{13}}\\) units.\n"
     ]
    }
   ],
   "source": [
    "for s_i in s_p:\n",
    "    print(s_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxy320/miniconda3/envs/multio1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [09:03<00:00, 67.93s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import __init__\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen2ForCausalLM\n",
    "target_model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B'\n",
    "target_model = AutoModelForCausalLM.from_pretrained(\n",
    "    target_model_name, torch_dtype=torch.float16,device_map=\"auto\", low_cpu_mem_usage=True, attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(target_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5468\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the distance, in units, between the points $(2, -6)$ and $(-4, 3)$? Express your answer in simplest radical form. Please reason step by step, and put your final answer within \\\\boxed{{}}. Alright, so I have this problem here where I need to find the distance between two points on a coordinate plane. The points are (2, -6) and (-4, 3). Hmm, okay, let me think about how to approach this. I remember something about the distance formula from my geometry class. I think it involves the coordinates of the two points. \\n\\nFirst, let me recall the distance formula. If I have two points, say (x1, y1) and (x2, y2), the distance between them is calculated using the square root of [(x2 - x1) squared plus (y2 - y1) squared]. So, it's like taking the differences in the x-coordinates and y-coordinates, squaring them, adding them together, and then taking the square root of that sum. That should give me the straight-line distance between the two points. \\n\\nAlright, so applying that to the points given here: (2, -6) and (-4, 3). Let me label the points to make it clearer. Let\\u2019s say (x1, y1) is (2, -6) and (x2, y2) is (-4, 3). \\n\\nNow, I need to find the differences in the x and y coordinates. So, starting with the x-coordinates: x2 - x1 is -4 - 2. Wait, is that right? Hold on, x2 is -4 and x1 is 2. So, subtracting x1 from x2 would be -4 - 2, which is -6. Hmm, but actually, in the distance formula, it doesn't matter if it's positive or negative because when we square it, the negative will become positive. So, maybe I should just compute the absolute difference to make it easier. \\n\\nBut wait, let me double-check. The formula is (x2 - x1)^2, so if x2 is less than x1, the result will be negative, but when squared, it becomes positive. So, whether I do -4 - 2 or 2 - (-4), the squared term will be the same. Let me compute both ways to be sure.\\n\\nFirst, x2 - x1: -4 - 2 = -6. Then, y2 - y1: 3 - (-6) = 3 + 6 = 9. So, squaring these, (-6)^2 is 36, and 9^2 is 81. Then, adding them together: 36 + 81 = 117. So, the distance is the square root of 117.\\n\\nBut wait, 117 doesn't look like a perfect square. Let me see if it can be simplified. Breaking down 117: 117 divided by 9 is 13, because 9 times 13 is 117. So, 117 is 9 times 13. Therefore, sqrt(117) can be written as sqrt(9*13), which is sqrt(9)*sqrt(13), and since sqrt(9) is 3, that becomes 3*sqrt(13). \\n\\nSo, putting it all together, the distance between the two points is 3 times the square root of 13 units. Let me just recap to make sure I didn't make any mistakes. I took the coordinates, subtracted them, squared each difference, added them, and then took the square root. That seems correct.\\n\\nJust to double-check, I can visualize the points on the coordinate plane. The first point is at (2, -6), which is in the fourth quadrant, and the second point is at (-4, 3), which is in the second quadrant. The distance between them should be a straight line across the plane, not along the x or y-axis. So, the calculation seems reasonable because it's not a horizontal or vertical line; it's diagonal, which would result in a distance that's a combination of horizontal and vertical distances.\\n\\nAlternatively, I can think of the horizontal distance between them as the difference in the x-coordinates, which is 2 - (-4) = 6 units. The vertical distance is the difference in the y-coordinates, which is 3 - (-6) = 9 units. So, the horizontal distance is 6, the vertical distance is 9. Then, the distance between the points would be the hypotenuse of a right-angled triangle with legs of 6 and 9. \\n\\nUsing the Pythagorean theorem, which states that in a right-angled triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides. So, hypotenuse squared is 6^2 + 9^2 = 36 + 81 = 117. Therefore, the hypotenuse is sqrt(117), which simplifies to 3*sqrt(13). \\n\\nOkay, so both methods give me the same result. That makes me feel confident that 3*sqrt(13) is the correct distance. Just to make sure, I can also compute sqrt(117) using a calculator. Let me do that. \\n\\nCalculating sqrt(117): 117 is between 100 and 121, so sqrt(117) should be between 10 and 11. Let me see: 10.8 squared is 116.64, which is just under 117. So, sqrt(117) is approximately 10.8167. Then, 3*sqrt(13) would be approximately 3*3.6055512755, which is approximately 10.8166538265. So, that matches up with the decimal approximation of sqrt(117). \\n\\nTherefore, both the exact value and the approximate decimal value check out. So, I think I can safely conclude that the distance between the points (2, -6) and (-4, 3) is 3*sqrt(13) units.\\n\\n**Final Answer**\\nThe distance between the points is \\\\boxed{3\\\\sqrt{13}} units.\\n</think>\\n\\nTo find the distance between the points \\\\((2, -6)\\\\) and \\\\((-4, 3)\\\\), we use the distance formula. The distance formula is given by:\\n\\n\\\\[\\n\\\\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\\n\\\\]\\n\\nLabeling the points as \\\\((x_1, y_1) = (2, -6)\\\\) and \\\\((x_2, y_2) = (-4, 3)\\\\), we calculate the differences in the coordinates:\\n\\n\\\\[\\nx_2 - x_1 = -4 - 2 = -6\\n\\\\]\\n\\\\[\\ny_2 - y_1 = 3 - (-6) = 3 + 6 = 9\\n\\\\]\\n\\nNext, we square these differences:\\n\\n\\\\[\\n(-6)^2 = 36\\n\\\\]\\n\\\\[\\n9^2 = 81\\n\\\\]\\n\\nAdding these squared differences:\\n\\n\\\\[\\n36 + 81 = 117\\n\\\\]\\n\\nTaking the square root of the sum:\\n\\n\\\\[\\n\\\\sqrt{117}\\n\\\\]\\n\\nWe simplify \\\\(\\\\sqrt{117}\\\\) by noting that 117 factors into \\\\(9 \\\\times 13\\\\):\\n\\n\\\\[\\n\\\\sqrt{117} = \\\\sqrt{9 \\\\times 13} = \\\\sqrt{9} \\\\times \\\\sqrt{13} = 3\\\\sqrt{13}\\n\\\\]\\n\\nThus, the distance between the points is \\\\(\\\\boxed{3\\\\sqrt{13}}\\\\) units.\"\n",
    "print(len(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2326\n"
     ]
    }
   ],
   "source": [
    "print(len(question+response_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import read_saved_results\n",
    "datas = read_saved_results('/home/wxy320/ondemand/program/speculative_thinking/results/MATH500_Qwen-math-1.5b_None_0.01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please reason step by step, and put your final answer within \\\\boxed{{}}',\n",
       " ' $\\\\overline{BC}$ is parallel to the segment through $A$, and $AB = BC$',\n",
       " ' What is the number of degrees represented by $x$?\\n\\n[asy]\\ndraw((0,0)--(10,0));\\ndraw((0,3)--(10,3));\\ndraw((2,3)--(8,0));\\ndraw((2,3)--(4,0));\\nlabel(\"$A$\",(2,3),N);\\nlabel(\"$B$\",(4,0),S);\\nlabel(\"$C$\",(8,0),S);\\nlabel(\"$124^{\\\\circ}$\",(2,3),SW);\\nlabel(\"$x^{\\\\circ}$\",(4',\n",
       " '5,3),S);\\n[/asy]<think>\\nPlease reason step by step, and put your final answer within \\\\boxed{{}}',\n",
       " ' $\\\\overline{BC}$ is parallel to the segment through $A$, and $AB = BC$',\n",
       " ' What is the number of degrees represented by $x$?\\n\\n[asy]\\ndraw((0,0)--(10,0));\\ndraw((0,3)--(10,3));\\ndraw((2,3)--(8,0));\\ndraw((2,3)--(4,0));\\nlabel(\"$A$\",(2,3),N);\\nlabel(\"$B$\",(4,0),S);\\nlabel(\"$C$\",(8,0),S);\\nlabel(\"$124^{\\\\circ}$\",(2,3),SW);\\nlabel(\"$x^{\\\\circ}$\",(4',\n",
       " \"5,3),S);\\n[/asy]\\nLet's solve the problem step-by-step\",\n",
       " '\\n\\n1',\n",
       " ' **Understand the Geometry:**\\n   - We have a triangle \\\\(ABC\\\\) with \\\\(AB = BC\\\\)',\n",
       " '\\n   - The angle at \\\\(A\\\\) is \\\\(124^\\\\circ\\\\)',\n",
       " '\\n   - Since \\\\(AB = BC\\\\), triangle \\\\(ABC\\\\) is isosceles with \\\\(\\\\angle BAC = \\\\angle BCA = x\\\\)',\n",
       " '\\n   - The sum of the angles in a triangle is \\\\(180^\\\\circ\\\\)',\n",
       " '\\n\\n2',\n",
       " ' **Calculate the Angles:**\\n   - The angle at \\\\(B\\\\) can be found using the fact that the sum of the angles in triangle \\\\(ABC\\\\) is \\\\(180^\\\\circ\\\\)',\n",
       " '\\n   - Since \\\\(\\\\angle BAC = x\\\\) and \\\\(\\\\angle BCA = x\\\\), we have:\\n     \\\\[\\n     x + x + 124^\\\\circ = 180^\\\\circ\\n     \\\\]\\n   - Simplifying, we get:\\n     \\\\[\\n     2x + 124^\\\\circ = 180^\\\\circ\\n     \\\\]\\n   - Solving for \\\\(x\\\\):\\n     \\\\[\\n     2x = 180^\\\\circ - 124^\\\\circ\\n     \\\\]\\n     \\\\[\\n     2x = 56^\\\\circ\\n     \\\\]\\n     \\\\[\\n     x = 28^\\\\circ\\n     \\\\]\\n\\nSo, the value of \\\\(x\\\\) is \\\\(28^\\\\circ\\\\)',\n",
       " \"\\n\\nLet's confirm this with Python and sympy:\\n\\n```python\\nimport sympy as sp\\n\\n# Define the variable\\nx = sp\",\n",
       " \"symbols('x')\\n\\n# Equation based on the sum of angles in the triangle\\nequation = sp\",\n",
       " 'Eq(2*x + 124, 180)\\n\\n# Solve the equation\\nsolution = sp',\n",
       " 'solve(equation, x)[0]\\n\\n# Print the solution\\nprint(solution)\\n```\\n```output\\n28\\n```\\nThe value of \\\\(x\\\\) is \\\\(\\\\boxed{28}\\\\)',\n",
       " '']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "i = 18\n",
    "question =\"Please reason step by step, and put your final answer within \\\\boxed{{}}. \" +datas[i]['question']+\"<think>\\n\"+datas[i]['generated_answer']\n",
    "s_p = question.split('.')\n",
    "s_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: your final answer within \\boxed{{}}.\n",
      "\n",
      "\n",
      "\n",
      " $\\overline{BC}$ is parallel to the segm\n",
      "response_text: Okay, so I've got this problem here: I need to find the\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  segment through $A$, and $AB = BC$.\n",
      "\n",
      "\n",
      "\n",
      " What is the number of degrees represent\n",
      "response_text: Okay, so I have this geometry problem here. Let me try to visualize\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: \",(2,3),SW);\n",
      "label(\"$x^{\\circ}$\",(4.\n",
      "\n",
      "\n",
      "\n",
      "5,3),S);\n",
      "[/asy]<think>\n",
      "Please reason ste\n",
      "response_text: Alright, so I've got this geometry problem here. Let me see if\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: your final answer within \\boxed{{}}.\n",
      "\n",
      "\n",
      "\n",
      " $\\overline{BC}$ is parallel to the segm\n",
      "response_text:  $\\overline{BC}$ is parallel to the segment through $A$,\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  segment through $A$, and $AB = BC$.\n",
      "\n",
      "\n",
      "\n",
      " What is the number of degrees represent\n",
      "response_text:  What is the number of degrees represented by $x$?\n",
      "\n",
      "[asy]\n",
      "\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: \",(2,3),SW);\n",
      "label(\"$x^{\\circ}$\",(4.\n",
      "\n",
      "\n",
      "\n",
      "5,3),S);\n",
      "[/asy]\n",
      "Let's solve the problem \n",
      "response_text: 5,3),S);\n",
      "[/asy]\n",
      "\n",
      "Okay, so I need to\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: et's solve the problem step-by-step.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "response_text: First, let's try to understand the given information and the diagram.\n",
      "\n",
      "We\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: ve the problem step-by-step.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.\n",
      "\n",
      "\n",
      "\n",
      " **Understand the Geometry:**\n",
      "   - We ha\n",
      "response_text: First, let's understand the given information:\n",
      "\n",
      "- Points A, B,\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: a triangle \\(ABC\\) with \\(AB = BC\\).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   - The angle at \\(A\\) is \\(124^\\circ\\\n",
      "response_text:    - Segment \\(\\overline{BC}\\) is parallel to the\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: The angle at \\(A\\) is \\(124^\\circ\\).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   - Since \\(AB = BC\\), triangle \\(ABC\\\n",
      "response_text:    - Segment \\(BC\\) is parallel to a segment through \\(A\\\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: ith \\(\\angle BAC = \\angle BCA = x\\).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   - The sum of the angles in a triangl\n",
      "response_text: Wait, no. If \\(AB = BC\\), then the angles opposite\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: gles in a triangle is \\(180^\\circ\\).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "response_text: 2.\n",
      "\n",
      "\n",
      "\n",
      " **Set Up the Equation:**\n",
      "   - \\(124\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: a triangle is \\(180^\\circ\\).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2.\n",
      "\n",
      "\n",
      "\n",
      " **Calculate the Angles:**\n",
      "   - The angl\n",
      "response_text:  **Set Up the Equation:**\n",
      "   - In triangle \\(ABC\\),\n",
      "\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: n triangle \\(ABC\\) is \\(180^\\circ\\).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   - Since \\(\\angle BAC = x\\) and \\(\\an\n",
      "response_text:    - So, \\(x + x + 124^\\circ\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  the value of \\(x\\) is \\(28^\\circ\\).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Let's confirm this with Python and sym\n",
      "response_text: **Final Answer**\n",
      "The number of degrees represented by \\(x\\) is \\\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: as sp\n",
      "\n",
      "# Define the variable\n",
      "x = sp.\n",
      "\n",
      "\n",
      "\n",
      "symbols('x')\n",
      "\n",
      "# Equation based on the su\n",
      "response_text: Symbol('x')\n",
      "\n",
      "# Set up the equation based on the sum of angles\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: ngles in the triangle\n",
      "equation = sp.\n",
      "\n",
      "\n",
      "\n",
      "Eq(2*x + 124, 180)\n",
      "\n",
      "# Solve the equation\n",
      "response_text: Eq(2*x + 124, 180)\n",
      "\n",
      "\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: \n",
      "# Solve the equation\n",
      "solution = sp.\n",
      "\n",
      "\n",
      "\n",
      "solve(equation, x)[0]\n",
      "\n",
      "# Print the solut\n",
      "response_text: solve(equation, x)\n",
      "\n",
      "print(solution)\n",
      "```\n",
      "\n",
      "The code will\n",
      "__________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: he value of \\(x\\) is \\(\\boxed{28}\\).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "response_text: **Final Answer**\n",
      "The number of degrees represented by \\(x\\) is \\\n",
      "__________________\n",
      "question: lue of \\(x\\) is \\(\\boxed{28}\\).\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "response_text: **Final Answer**\n",
      "The number of degrees represented by \\(x\\) is \\\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "from explore_diff2 import decoding_chat\n",
    "\n",
    "question = ''\n",
    "for i in range(len(s_p)):\n",
    "    s_i = s_p[i]\n",
    "    question = question + s_i+'.\\n\\n\\n\\n'\n",
    "    # response_text, corrected_tokens, num_tokens, record_tokens, avg_probabilities = decoding_chat(\n",
    "    #     target_model, tokenizer, question, '', \n",
    "    #     temperature=0.6, topk=0, topp=0.95, max_tokens=15\n",
    "    # )\n",
    "    # print('question:', question[-40:]+s_p[i+1][:40])\n",
    "    # print('response_text:', response_text)\n",
    "    # print([r['token'] for r in record_tokens])\n",
    "    # print('__________________')\n",
    "    # Tokenize input\n",
    "    input_ids = tokenizer.encode(question, return_tensors='pt').to(target_model.device)\n",
    "\n",
    "    # Generate response\n",
    "    output_ids = target_model.generate(\n",
    "        input_ids,\n",
    "        temperature=0.6,\n",
    "        top_k=0,\n",
    "        top_p=0.95,\n",
    "        max_length=input_ids.shape[1] + 15,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    # Decode response\n",
    "    response_text = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    print('question:', question[-40:] + (s_p[i+1][:40] if i + 1 < len(s_p) else ''))\n",
    "    print('response_text:', response_text)\n",
    "    print('__________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the smallest positive perfect cube that can be written as the sum of three consecutive integers? Please reason step by step, and put your final answer within \\boxed{{}}. Okay, so I need to find the smallest positive perfect cube that can be written as the sum of three consecutive integers. Hmm, let's break this down step by step. \n",
      "\n",
      "First, let's clarify what is meant by consecutive integers. Consecutive integers are numbers that follow each other in order without any gaps. So, if I denote the first integer as n, then the next two consecutive integers would be n+1 and n+2. Therefore, the sum of these three integers would be n + (n+1) + (n+2).\n",
      "\n",
      "Let me write that down:\n",
      "\n",
      "Sum = n + (n + 1) + (n + 2)\n",
      "\n",
      "Simplifying this expression:\n",
      "\n",
      "Sum = n + n + 1 + n + 2\n",
      "Sum = 3n + 3\n",
      "\n",
      "So, the sum simplifies to 3n + 3. Hmm, that's 3(n + 1). Interesting. So, the sum is three times (n + 1). \n",
      "\n",
      "Now, the problem states that this sum must be a perfect cube. A perfect cube is a number that can be expressed as some integer raised to the power of three. So, we're looking for a perfect cube, let's call it C, such that C = 3(n + 1). \n",
      "\n",
      "Since C is a perfect cube, it can be written as k\\u00b3 where k is a positive integer. So, we have:\n",
      "\n",
      "k\\u00b3 = 3(n + 1)\n",
      "\n",
      "Which means that 3 divides k\\u00b3. Since 3 is a prime number, if 3 divides k\\u00b3, then 3 must divide k. So, let me write that down: k = 3m where m is an integer. \n",
      "\n",
      "Substituting back into the equation:\n",
      "\n",
      "(3m)\\u00b3 = 3(n + 1)\n",
      "27m\\u00b3 = 3(n + 1)\n",
      "\n",
      "Divide both sides by 3:\n",
      "\n",
      "9m\\u00b3 = n + 1\n",
      "\n",
      "So, n + 1 = 9m\\u00b3, which implies that n = 9m\\u00b3 - 1.\n",
      "\n",
      "Therefore, the three consecutive integers are:\n",
      "\n",
      "First integer: n = 9m\\u00b3 - 1\n",
      "Second integer: n + 1 = 9m\\u00b3\n",
      "Third integer: n + 2 = 9m\\u00b3 + 1\n",
      "\n",
      "Let me check with m = 1:\n",
      "\n",
      "n = 9(1)\\u00b3 - 1 = 9 - 1 = 8\n",
      "So, the three consecutive integers are 8, 9, 10.\n",
      "\n",
      "\n",
      "__________________\n",
      "What is the smallest positive perfect cube that can be written as the sum of three consecutive integers? Please reason step by step, and put your final answer within \\boxed{{}}. Okay, so I need to find the smallest positive perfect cube that can be written as the sum of three consecutive integers. Hmm, let's break this down step by step. \n",
      "\n",
      "First, let's clarify what is meant by consecutive integers. Consecutive integers are numbers that follow each other in order without any gaps. So, if I denote the first integer as n, then the next two consecutive integers would be n+1 and n+2. Therefore, the sum of these three integers would be n + (n+1) + (n+2).\n",
      "\n",
      "Let me write that down:\n",
      "\n",
      "Sum = n + (n + 1) + (n + 2)\n",
      "\n",
      "Simplifying this expression:\n",
      "\n",
      "Sum = n + n + 1 + n + 2\n",
      "Sum = 3n + 3\n",
      "\n",
      "So, the sum simplifies to 3n + 3. Hmm, that's 3(n + 1). Interesting. So, the sum is three times (n + 1). \n",
      "\n",
      "Now, the problem states that this sum must be a perfect cube. A perfect cube is a number that can be expressed as some integer raised to the power of three. So, we're looking for a perfect cube, let's call it C, such that C = 3(n + 1). \n",
      "\n",
      "Since C is a perfect cube, it can be written as k\\u00b3 where k is a positive integer. So, we have:\n",
      "\n",
      "k\\u00b3 = 3(n + 1)\n",
      "\n",
      "Which means that 3 divides k\\u00b3. Since 3 is a prime number, if 3 divides k\\u00b3, then 3 must divide k. So, let me write that down: k = 3m where m is an integer. \n",
      "\n",
      "Substituting back into the equation:\n",
      "\n",
      "(3m)\\u00b3 = 3(n + 1)\n",
      "27m\\u00b3 = 3(n + 1)\n",
      "\n",
      "Divide both sides by 3:\n",
      "\n",
      "9m\\u00b3 = n + 1\n",
      "\n",
      "So, n + 1 = 9m\\u00b3, which implies that n = 9m\\u00b3 - 1.\n",
      "\n",
      "Therefore, the three consecutive integers are:\n",
      "\n",
      "First integer: n = 9m\\u00b3 - 1\n",
      "Second integer: n + 1 = 9m\\u00b3\n",
      "Third integer: n + 2 = 9m\\u00b3 + 1\n",
      "\n",
      "Let me check with m = 1:\n",
      "\n",
      "n = 9(1)\\u00b3 - 1 = 9 - 1 = 8\n",
      "So, the three consecutive integers are 8, 9, 10.\n",
      "\n",
      "To find the smallest positive perfect cube that can be\n",
      "[{'token_id': [1249, 32313, 71486], 'probs': [0.3065232038497925, 0.47901102900505066, 0.21446575224399567], 'token': ['To', 'Okay', 'Alright']}, {'token_id': [1477], 'probs': [1.0], 'token': [' find']}, {'token_id': [279], 'probs': [1.0], 'token': [' the']}, {'token_id': [24632], 'probs': [1.0], 'token': [' smallest']}, {'token_id': [6785], 'probs': [1.0], 'token': [' positive']}, {'token_id': [4727], 'probs': [1.0], 'token': [' perfect']}, {'token_id': [23739], 'probs': [1.0], 'token': [' cube']}, {'token_id': [429], 'probs': [1.0], 'token': [' that']}, {'token_id': [646], 'probs': [1.0], 'token': [' can']}, {'token_id': [387], 'probs': [1.0], 'token': [' be']}]\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "from explore_diff2 import decoding_chat\n",
    "\n",
    "question = \"What is the smallest positive perfect cube that can be written as the sum of three consecutive integers? Please reason step by step, and put your final answer within \\\\boxed{{}}. Okay, so I need to find the smallest positive perfect cube that can be written as the sum of three consecutive integers. Hmm, let's break this down step by step. \\n\\nFirst, let's clarify what is meant by consecutive integers. Consecutive integers are numbers that follow each other in order without any gaps. So, if I denote the first integer as n, then the next two consecutive integers would be n+1 and n+2. Therefore, the sum of these three integers would be n + (n+1) + (n+2).\\n\\nLet me write that down:\\n\\nSum = n + (n + 1) + (n + 2)\\n\\nSimplifying this expression:\\n\\nSum = n + n + 1 + n + 2\\nSum = 3n + 3\\n\\nSo, the sum simplifies to 3n + 3. Hmm, that's 3(n + 1). Interesting. So, the sum is three times (n + 1). \\n\\nNow, the problem states that this sum must be a perfect cube. A perfect cube is a number that can be expressed as some integer raised to the power of three. So, we're looking for a perfect cube, let's call it C, such that C = 3(n + 1). \\n\\nSince C is a perfect cube, it can be written as k\\\\u00b3 where k is a positive integer. So, we have:\\n\\nk\\\\u00b3 = 3(n + 1)\\n\\nWhich means that 3 divides k\\\\u00b3. Since 3 is a prime number, if 3 divides k\\\\u00b3, then 3 must divide k. So, let me write that down: k = 3m where m is an integer. \\n\\nSubstituting back into the equation:\\n\\n(3m)\\\\u00b3 = 3(n + 1)\\n27m\\\\u00b3 = 3(n + 1)\\n\\nDivide both sides by 3:\\n\\n9m\\\\u00b3 = n + 1\\n\\nSo, n + 1 = 9m\\\\u00b3, which implies that n = 9m\\\\u00b3 - 1.\\n\\nTherefore, the three consecutive integers are:\\n\\nFirst integer: n = 9m\\\\u00b3 - 1\\nSecond integer: n + 1 = 9m\\\\u00b3\\nThird integer: n + 2 = 9m\\\\u00b3 + 1\\n\\nLet me check with m = 1:\\n\\nn = 9(1)\\\\u00b3 - 1 = 9 - 1 = 8\\nSo, the three consecutive integers are 8, 9, 10.\\n\\n\" #Sum: 8 + 9 + 10 = 27\\n\\n27 is indeed a perfect cube (3\\\\u00b3). So, that seems to work. \"\n",
    "response_text, corrected_tokens, num_tokens, record_tokens, avg_probabilities = decoding_chat(\n",
    "    target_model, tokenizer, question, '', \n",
    "    temperature=0.7, topk=0, topp=0.95, max_tokens=10\n",
    ")\n",
    "print(question)\n",
    "print('__________________')\n",
    "print(question+response_text)\n",
    "print(record_tokens)\n",
    "print('__________________')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multio1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
